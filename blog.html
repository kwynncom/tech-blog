<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<title>Kwynn's tech blog</title>

<script>

var KWYNN_COM_SOUND_2020_1 = false;

function play2020_1(toggle) {
      const path = 'https://kwynn.com/t/20/11/audio/';
      const name = 'ubuntu-20-04-1-desk-x64-95-seconds.wav';
	  if (toggle !== false) {
	      const sound = new Audio(path + name); 
		  KWYNN_COM_SOUND_2020_1 = sound;
	      sound.play();
		} else KWYNN_COM_SOUND_2020_1.pause();
}
</script>

<style>

body { font-family: sans-serif }
h3   { margin-top: 1.7ex; margin-bottom: 0ex; font-size: 125%; }
h4   { font-size: 112%; margin-top: 0.7ex; margin-bottom: 0.6ex; }
h5   { font-size: 105%; margin-bottom: 0ex;  margin-top: 0.4ex; }
h6   { font-size: 102%; margin-bottom: 0ex;  margin-top: 1.3ex;}
p    { margin-top: 0.9ex; margin-bottom: 1.3ex; }
pre  { margin-top: 0; margin-bottom: 0; }
h1   { margin-top: 0; margin-bottom: 0; }
ul	{margin-top: 0.5ex}
li   { margin-bottom: 0.7ex; }
</style>
</head>
<body>
<p style='margin-bottom: 0.1ex; '><a href='../../../'>home</a></p>
<section>

<div style='margin-bottom: 2.5ex; '>
<h1  style='display: inline-block'>tech blog</h1>
<div style='display: inline-block; margin-left: 0.6ex; position: relative; top: 0.9ex; '>
    
<a href='https://validator.w3.org/check?uri=https://kwynn.com/t/7/11/blog.html'>
                                                        
        <img style='transform: scale(0.81, 0.81);' src="../../5/02/html5_valid.jpg" alt="HTML5 valid" width="103" height="36" /></a>
</div>
</div>
    
<p>Drafts / previous versions of <a href='https://github.com/kwynncom/tech-blog'>this page are on GitHub</a>.  For time zone purposes, I am near Atlanta and use my 
local timezone.  Atlanta is the same as New York (America/New_York), or UTC -5 / Eastern Standard Time (EST) in winter and UTC -4 during Daylight Saving Time / 
Eastern Daylight Time (EDT) / summer time, which is in effect almost 8 months out of the year.</p>

<p>Starting sometime in December, 2021, many entries are in response to one of my apprentices, so he is the "you" I'm speaking to initially.
    
</p>

<section>
    <h3>January 14, 2022</h3>
    
    <h4>Ubuntu package problems and some solutions</h4>
    
    <p>My currently active apprentice is having package (software install) problems.  These are some thoughts.</p>
    
    <p>For one, when installing Ubuntu and probably other Linux distributions / "distros" / sub-brands, the 3rd party / proprietary packages / 
        software are probably not worth it.  That's one question Ubuntu asks by default upon install. I suspect that's the root of his problem.  
        Specifically: when he runs "sudo apt install --fix-broken" these 2 packages have problems: "Errors were encountered while processing:
        libgl1-amdgpu-mesa-dri:amd64 libgl1-amdgpu-mesa-dri:i386"
    </p>
    
    <p>When I run "apt list --installed | grep libgl1" I get libgl1-mesa-dri and libgl1/impish.  I am reasonably sure this means he installed 
        AMD specific drivers and I did not.  I can run <a href='https://www.flightgear.org/'>FlightGear</a> reasonably well on very old hardware.  
        I'd have to go digging for my graphics card specs, but I remember it only has 1 GB RAM which is old.  Maybe the proprietary driver would 
        help, but, as above, it's probably not worth the cost benefit, and I should get better hardware when I can.
     </p>
         
    <p>I suspect he's also having problems because Ubuntu is pulling away from i386 (32 bit).  That is an argument for installing the latest 
        Ubuntu rather than the LTS version, but that's another discussion.
   </p>
   
   <p>The GUI / Gnome / desktop was probably almost literally making noises about a package problem.  Whether it was or wasn't, there is an argument to 
       be made for checking by hand perhaps once a week:
       </p>
       
       <pre>
sudo apt update
sudo apt dist-upgrade
       </pre>
   
       <p>If you get the package error message, do not ignore it.  In fact, it's probably time to backup your computer.  This has not happened to me 
           often, but it has gotten out of hand perhaps 3 times in 12 years.  Usually I was asking for it, but that's another discussion.  (Below I 
           list one instances of trying to downgrade PHP.)
      </p>
      
      <p>In any event, solve the package error ASAP.
          
      </p>
      
      <p>The solution to the problem is usually to remove the packages in question, and really thoroughly remove them.  I can't think of a way to 
          quickly set this up to demonstrate, so I'll have to refer ya'll to Big Evil Goo.  The commands involve such terms as "purge," and then I 
          can't remember if the usual term is delete or remove.  
      </p>
      
      <p>Note that you may have to use the dpkg command for this process, and you may have to use aptitude rather than apt, although if it's not 
          already installed, you probably can't install anything while that error is pending.
       </p>
       
       <p>Command list:</p>
       
       <pre>
# a list of commands or their close equivalents for package management
# use these 2 often, perhaps once a week or more:
sudo apt update
sudo apt dist-upgrade
# the rest are not harmful but only useful in context
sudo apt install --fix-broken
# I have never used the audit option before; I was simply looking for something harmless but to remind one 
# of the dpkg command
# You may not have this package at all.  
sudo dpkg --audit libgl1-mesa-dri
apt list --installed      
# which package did x file come from:
# this is a small part of answering another question of yours
dpkg -S /usr/bin/find
# not directly relevant, but in answer to another issue
tail -n 20 /var/log/syslog       </pre>
       
<p>For problems with running software as opposed to their packages, many pieces of software have a verbose mode or variously levels of 
    verbosity.  Sometimes you can shut down the systemctl version of the program and run it "by hand" with the direct command and verbose turned on.

</p>

<p>You asked if some of these commands are the direct equivalent of what the GUI does.  Well, update and dist-upgrade are the equivalent of some of it, 
    and as you discovered, sometimes doing it by hand is an improvement because the GUI will lose track of changing IP addresses.  That is, always do 
    an update before an upgrade.
</p>

<p>The above will not upgrade you a full version such as 21.04 to 21.10.  There is of course a command line for that, too.  
    
</p>

<p>You mentioned digging around on various errors in the syslog.  Unless the timing makes it certain it's what you need to focus on, I'm sure there 
    is all sorts of junk in syslog that a perfectly running systems spits out.  You could spend forever chasing such things.
    
</p>

<h4>software (un)installs versus Satan's OS (SOS) / Linux file organization</h4>

<p>I only have a fuzzy understanding of how the files are laid out--libraries, binaries, datafiles, etc.  In the immediate context, solve your package 
    problem first.  I wasn't trying to 
    discourage you from learning more; I was just saying solve that problem first.  I don't think a better understanding of the overall system will 
    help you solve the immediate problem.
</p>

<p>You pointed out in SatanSoft that you can delete software more easily.  There are a number of reasons for that.  For one, almost all software 
is using SOS code.  In Linux, you have an ocean of free software to choose from.  The Nu HTML Validator uses both Java and Python, for example.  
There are so many choices of how to build software that it leads to so many more packages.  Open source software is build on layers and layers and 
layers of open source software.  The dependency graph is much more complex.
    </p>
    
<p>For a number of reasons, SOS apps are already compiled for a known OS, and SOS takes care of any small differences in hardware.  The software is 
    already a more-or-less standalone set of files when it ships. 
    Lots of Linux software is interpreted rather than compiled, so its dependencies are not compiled in.  Also, Linux runs on such a variety of 
    hardware that an app couldn't compile for a known hardware target anyhow.
</p>

<p>Another way of phrasing the above is that SOS software can make assumptions about what libraries are available because those libraries come with 
    SOS.  With Linux, one can make very few assumptions, so one has to make a package dependency list which is turn invokes other dependencies.  
</p>

<p>Again, many more choices and possibilities.   
</p>

<p>Linux packages do have an uninstall.  I just haven't listed the command because I don't have anything I want to uninstall that badly.  Also, 
    with Linux, how deep down the dependency tree should the uninstall go?  It can't uninstall stuff that other software depends upon.  
</p>

<p>Upon thought, if you continue to have trouble, I can do LOTS of uninstalling on one of my partitions.  This was weeks ago when I tried to 
    downgrade to PHP 7.4.  I used a PPA that I had success with before going forward, but going backward got out of hand quickly.  I wound up 
    with errors such as "yours" of the day, and I abandoned ship and built another partition.  I can go back to that old partition and start 
    stripping it down to get rid of stuff that doesn't work anyhow.  I did NOT lose data.  It would be difficult, in fact, to use data due to 
    package issues, even if the system was unbootable.  You could still get at the data with another running system whether on another parition or a
    USB.
</p>




<h4>several emails ago</h4>

<p>You said that you've read some of these entries 3 times.  That doesn't surprise me.  In case there is doubt, I realize that a lot of this 
    simply cannot make sense yet because you don't have the context.  Hopefully in a small number of months, you can re-read these and get more out of 
    it.

</p>
       
       
   
    
</section>


<section>
    <h3>January 13, 2022 - broken HTML validator - continuing 02:38</h3>
    
    <p>I have the <a href='https://github.com/validator/validator'>Nu HTML validator</a> working locally.
        I cloned it to /opt and then this works: python3 ./checker.py all and then python3 ./checker.py run .
        
        
    </p>
    
    <p>Days ago nattered on about the referer HTTP request header as it applied to the W3 HTML validator.  Coincidentally, I just 
        realized that the referer is essentially broken for validation purposes.  It appears that in March, 2021 (version 87), Firefox
        started to 
        <a href='https://blog.mozilla.org/security/2021/03/22/firefox-87-trims-http-referrers-by-default-to-protect-user-privacy/'>"trim" 
            the referer</a> down to the domain name.  It would appear that I have a lot of work to do to fix this. 
    </p>
    
    <p>I already fixed it for this page, or at least I gave it the quick-and-dirty fix.  I just hard-coded the URL to kwynn.com.  
       That won't work for a fully online test system--that is, a test system accessible from the outside.  
    </p>
    
    <p>The right solution is JavaScript populating the URI / URL on page load.  But I have to add that JavaScript to 156 pages 
        according to my grep -R.  That is one of the rationales for a single page system--route all page requests through one 
        program that adds / changes whatever needs adding / changing.  
        
    </p>
    
    
    <h3>January 12, 2022, one of several entries today, starting this at 23:26</h3>
    
    <p>Updated 23:47 with some answers.  Updated 23:54 regarding http://validator....
        
    </p>
    
    <p>I'm consider several changes to my Apache config, several of which I've tested.  Some notes below.  I am not using newlines in a realistic way--that is, the 
        following is not precisely correct.</p>
    
    <ul>
        <li>I must fix http://validator references before doing the SSL rewrite</li>
        <li>"$ sudo apachectl configtest" - keep this in mind</li>
        <li>apachectl above seems to want you to define the ServerName in apache2.conf itself, in addition to elsewhere</li>
        <li>This works quite nicely: &lt;VirtualHost *:80&gt;Include sites-available/common.conf</li>
        <li>Does certbot need ServerName in sites-available if it's in Apache.conf? - YES, if you want to auto-discover.  But it CAN be in the include / common file.</li>
        <li>Will certbot find my email address if it's in the include file?  Yes.</li>
        <li>If you are already in *:80, then everything needs rewriting: RewriteEngine On   RewriteRule ^ https://%{HTTP_HOST}%{REQUEST_URI} [L,NE]</li>
        <li>Apache Rewrite Rule config flags: L is the last rule, NE is no escape of chars in the URL because you want to pass them on as-is</li>
        <li>If you're in an .htaccess file:  RewriteCond %{HTTPS} !=on  and perhaps ReWriteRule ^(.*)$ but I think ^ above would work fine</li>
        <li>Note that the above is for a 302 (temp) rather than 301 (perm).  I can do 301 later.</li>
    </ul>
    
</section>

<section>
    <h3>January 12, 2022, one of several entries today, starting 20:43, first posted 22:20</h3>
    
    <p>(I made small revisions at 22:38.)</p>
    
    <p>And back to my web dev Q&A with my apprentice.  He is the "you" to whom I'm originally speaking.</p>
    
    <p>First, something I should emphasize again about sending email.  Among basic features that should be simple, it is 
        one of the harder things I've done over the years.  I'm sure I've done lots of harder things, but nothing that is 
        both such a basic feature and so hard.
        Part of the problem is that there are Federal and presumably 
        many other laws around the world around spam, so the providers are very cautious.
    </p>
    
    <p>To clarify for myself and everyone else, your point about "from scratch" was about memorizing stuff.  There are 
        basic things I've done several thousand times that I still look up in some sense of the term "look up" (see below).  
        That's in part because PHP is inconsistent in the order of function arguments in a few places, but that's not by 
        any means the only example.
     </p>
     
     <p>I'm trying to stop beating on <a href='https://www.php.net/'>php.net</a> and trying to grep -R my own code.  I will 
         suggest something that I have only done sporadically:
         </p>
         
    <p>Create your own page and / or your own program that demonstrates all the things you keep looking up.  Exaggerate the 
        clarity of the variables.  I tend to use very short variable names because I get tired of typing them, but I should 
        take my own advice when I'm giving examples.
    </p>
    
    <p>I think it'd be very funny and geeky and cool to have one bigger and bigger program that demonstrates all of the 
        little "primitives" of coding, where I'm using the term primitives to mean the syntax, the functions, the order of the 
        function args and what they are, snippets of doing a bunch of simple little things, etc.
    </p>
    
    <p>Alternatively, I have downloaded all the PHP doc, but I never fully installed it.  I've also considered installing it 
        on Kwynn.com.  I've also also (sic) considered installing the "Nu" 
        <a href='https://validator.w3.org/'>HTML validator that W3</a> runs.  Recently I noticed a reference to installing it 
        yourself.
     </p>
     
     <p>Other than my not understanding the memorizing key to your question, we seem to be on the same page.
         
     </p>
     
     <p>What, me using uncommon words such as Quixotic?  I would never do such a thing.</p>
     
     <p>WINE is a mixed bag.  Around 5 years ago an apprentice got <i>Call of Duty</i> working in Linux running on iCult hardware.
         I don't remember if it was perfect, but it at least worked fairly well.
I've had some success with WINE, but I'd say it's still a pain.  A potential apprentice recently mentioned 
<a href='https://zorin.com/os/'>Zorin Linux</a>, which is based on Ubuntu.  Apparently the emphasis is on making it easier for 
people to migrate from SatanSoft.  The <a href='https://en.wikipedia.org/wiki/Zorin_OS'>Zorin WikiPedia article</a> mentions
both WINE and PlayOnLinux that Zorin encourages.
     </p>
     
     <h4>HTTP headers</h4>
     <p>Regarding the "header thing" or the "DO NOT CLOSE PHP TAGS UNLESS..." thing, which I got into in the last few weeks, 
this issue is a special case, just like sending email is a special case.  The email thing you came up with on your own, in that you 
brought it to me.  The tag thing I'm shoving a screeching at you because it has caused me enormous damage.  For one, it's 
a special case because it goes in the "hear me now and believe me [and understand me] later" category.  It's probably not 
worth taking the time to reproduce the dreaded "...cannot be changed after headers have already been sent" error.  With 
that said, I'll give some explanation.
     </p>
     
     <p>Below is a relevant example.  I have removed a number of lines to make it smaller.</p>
     
     <pre>$ curl -i https://kwynn.com/robots.txt
HTTP/1.1 200 OK
Date: Thu, 13 Jan 2022 02:11:22 GMT
Server: Apache/2.4.41 (Ubuntu)
Last-Modified: Sun, 04 Oct 2020 04:13:01 GMT
ETag: "195-5b0d094ed72a3"
Content-Length: 405
Content-Type: text/plain

User-agent: *
Disallow: /t/8/01/wx/wx.php
Sitemap: http://kwynn.com/t/1/01/sitemap.xml
Sitemap: https://kwynn.com/t/20/10/sitemap_begin_2020.xml</pre>
     
<p>When your PHP runs in "web mode," it is usually responding to an HTTP GET or POST, which I'll demonstrate more specifically 
    in a moment.  
It must respond to an HTTP request with a result specified by the protocol (HTTP).  It's doing some of that behind the scenes.  
PHP *MUST* generate headers for the browser to accept the result.  The curl command above generates a GET, and that is the result 
including the headers, minus a few lines.  I'm not sure which of the above are absolutely required in an HTTP response, but, 
whatever the case, the browser is expecting a number of lines and a number of types of lines and then a double newline.  
Everything after the double newline is the body which is often the HTML itself.  If you output anything, even accidentally, 
from PHP before the proper headers go out, you may break your page.
</p>

<p>If that's all there were to the "cannot be changed" issue, it wouldn't be so bad.  But, believe me, at least years ago 
    the results were unpredictable to the point that it seemed like a virus.  (A real computer virus that does damage to 
    data, as opposed to fake viruses that do nothing to people.)  At that time, I was just starting to do hard-core PHP dev, and I could not 
    figure out what was going on.  (I think I already was using a debugger.)  I'm sure I Googled, but I guess it still took me a 
    while to figure out what was going on.
</p>
     
<p>I was going to show you what I thought was a more "pure" example of an HTTP GET, but it doesn't work quite like I expected.  
I think that's because I'm not sending a proper HTTP request packet, and my brief attempts to do so didn't get me anywhere.  
But it hopefully the follwoing gives you more insight.  Note that I'm removing parts of HTML tags because it seems that the validator doesn't like 
CDATA, or maybe CDATA has been deprecated.
</p>
<pre>$ telnet kwynn.com 80
Trying 2600:1f18:23ab:9500:acc1:69c5:2674:8c03...
Connected to kwynn.com.
Escape character is '^]'.
GET /
!DOCTYPE html
html lang="en"
head
[...]
titleKwynn's website/title
[...]
/body
/html</pre>

<p>You can see the request and response headers in control-shift-I network, and there are other ways to get at it.  Note that 
    if you ever parse a raw HTTP response, all of the newlines are old-fashioned \r\n rather than just \n in Linux.  This becomes
    important if you try to separate header and body.  I parse it with "$hba = explode("\r\n\r\n", $rin);" on 
    <a href='https://github.com/kwynncom/github-activity-web-widget/blob/f234e9509064c61fd6f159fac21a57227f2270c5/getActual.php'>line 34</a>.
    
</p>

<p>  As for your having no experience with PHP and "header()," hopefully I've shown 
    that this is a much wider question than PHP.  Everything on the web uses headers.  
    
</p>

<p>As for the header() PHP function, that lets you add headers when needed.  I hope you have realized that all headers must 
    come before the main body of the output.  :)   Reasons I've had to use headers are:
</p>

<ul>
    <li>"Content-Type: application/json" - You need to tell the recipient it's not HTML.</li>
    <li>You output a lot of headers if you're doing a direct download such as PHP reading an audio file and then allowing a 
        download, or downloading a PDF.  I'd have to go digging for those examples, or I'm sure you'd find them.
        </li>
    <li>If I ever decide to rewrite all URLs to a "single page" system like WordPress does, I should output my own modified 
        dates and etags because PHP assumes the output is dated "now," when the date should be when the content changed.
    </li>
    <li>header('Location: https://' . $_SERVER['HTTP_HOST'] . $_SERVER['REQUEST_URI']); -- that's one way of doing a redirect, 
        in this case to HTTPS from HTTP, although this is not the best modern method for forcing HTTPS.
        
    </li>
    
    <li>You have to use headers in cases of cross-scripting issues / CORS / Cross-origin resource sharing.  Browser security 
        says the browser can only accept data from one domain unless you output headers telling it that cross-origins are OK.
     </li>
</ul>

<p>Hopefully that gives you a lot more under the hood.
</p>

<h4>kwas()</h4>

<p>In your kwas() example, you'll want a line before exit(0); that does echo('OK' . "\n");  I assume it's not outputting 
    anything because you got sendmail installed, and sendmail is accepting emails for processing and thus mail() returns true.  
    (As I said at great length below, that in itself won't get you much closer to sending an email, but anyhow...)
</p>

<p>kwas() is about checking your assumptions ALL THE TIME.  In your example, you didn't output anything in the event of 
    success.
</p>

<p>You did incorporate kwutils into your code just fine.  You just didn't do anything to output in the event of success.
</p>

<p>There is more to say on this, but I'll wait until you have more examples.    
</p>

<p>Here is an example of one consequence of require_once'ing kwutils.  First without then with:</p>

<pre>&lt;?php
$a = [];
$b = $a['a'];
echo('got here' . "\n");
// RESULT:
[stderr in red:] PHP Warning:  Undefined array key "a" in /home/k/sm20/frag/kwuex.php on line 4
got here

&lt;php // new program
require_once('/opt/kwynn/kwutils.php');
// then same 3 lines as above
// RESULT:
ERROR: kwuex.php LINE: 4 - Undefined array key "a" /home/k/sm20/kwuex.php</pre>

<p>When I change the error handler in kwutils.php, warnings become fatal errors.  I am certain this is the right 
    answer in the real world.  Just about all of my own code uses it.  I haven't been able to fully prove it's the right 
    answer in my main paid project because Drupal throws warnings right, left, and center.  But the new version is most certainly 
    going to take the position of forcing fatal errors.  I made this change in response to annoyance at Drupal throwing 
    warnings and continuing execution.
</p>

<p>There is as always more to say, but that will do for now.
    
</p>

</section>

<section>
    <h3>January 12, 2022, posted at 20:33 (started 18:11) - installing an HTTPS SSL cert locally</h3>
    
    <p>This is my second entry started today and the 3rd entry that either started or bled into today.
        
    </p>
    
    <p>You have to have a domain for an SSL cert. For local dev purposes, I highly recommend using 
        a subdomain (testinglocal.example.com) even if you're not using the base domain.  One reason is that when in 
        development, you change things so much that you might go over certbot's limits on certs.  It's something like 5 certs 
        a week for a given fully qualified domain.  Thus, if you're using a subdomain, you can just use another subdomain 
        (testinglocal2.example.com) rather than losing access to the base domain for several days.  This isn't theory.  I 
        went over the limit several months ago.  It snuck up on me.
      </p>
    
    <p>As I muck around with my internet service provider's modem / router, I'm finding that my local system does 
        not have a 32 bit IPv4 identity.  This is important for firewall reasons.  So, let's see if this works: 
        "$ ifconfig  | grep global"  That results in 3 global IPv6 addresses.  The first one didn't seem to work, then I added 
        a second.  Then as I ran curl from kwynn.com (external to my local system) and found which address it was using, I went 
        back down to only one IPv6 address in the DNS AAAA record for the subdomain.  You register DNS records with your domain 
        name registrar.  I use <a href='https://www.hover.com/'>Hover</a>.
    </p>
    
    <p>My router's ping / icmp settings were somewhat confusing.  The setting 
        "Drop incoming ICMP Echo requests to Device LAN Address"
        had to be turned off for the "Global Unicast IPv6 Address" of the router itself to respond to ping.  In order to ping 
        my local system, "Reflexive ACL" had to be turned off.  That needs to stay off through the certbot verification because 
        the process needs a system passively listening on port 80.  
   </p>

   <p>Turn off any active local sites except the one in question.  That is, disable them in Apache then restart.  Below, 
       "irrelevant" is the site / virtual host defined in /etc/apache2/sites-available/irrelevant.conf
   </p>
   
   <pre>sudo a2dissite irrelevant
sudo systemctl reload apache2</pre>
       
      
   
            <p>I set the one active virtual host to simply be receiving *:80: &lt;VirtualHost *:80&gt;  Putting IP address in 
                the 
                VirtualHost top line 
        did not work--certbot did not find anything listening, even though curl worked.  You also need to set the ServerName 
        to the fully qualified domain.  Don't forget to restart Apache.
        
    </p>
    
    
    <p>Note that the ufw default settings were not causing a ping problem.  As for getting ready for the certbot:
        "$ sudo ufw allow http" and "$ sudo ufw allow https"  
     </p>

    <p><a href='https://certbot.eff.org/'>Certbot home</a>, and 
        <a href='https://certbot.eff.org/instructions?ws=apache&os=ubuntufocal'>relevant-to-me instructions</a>.
        
    </p>
     
     <p>First, do the "dry run": "$ sudo certbot -v certonly --apache --dry-run"  Then do the real thing: "sudo certbot --apache"
         
     </p>

     
     <p>Once SSL is working, you can put an entry like this in /etc/hosts:</p>
     <pre>127.0.0.1   blah.example.com</pre>
     
     <p>Once you do that, you can reverse all the security and even the AAAA DNS record because the site is now self-contained.
         Note that you have to open things up again to renew the security cert before 90 days.  
         
     </p>
     
     <p>If needed, set your firewall back to "Reflexive ACL" on.  Then "$ sudo ufw status numbered  ".  Assuming you want to 
         delete 
         all the rules, "sudo ufw delete 1" to delete all the rules until they're all gone.  Delete the AAAA record.
         
     </p>
     
     <p>For cleanup later, when you're done with the cert: $ sudo certbot delete --cert-name blah.example.com
              </p>

</section>


<section>
    <h3>January 12, 2022 (AM) - the concept of "from scratch"</h3>
    
    <p>Note that my January 11 entry on email continued into today, January 12.  This is a new entry started on Jan 12.</p>
    
    <p>Yet again I'm continuing my web dev Q&A, usually answering emails from one apprentice.  He is the "you" when I use "you."   </p>
    
    <p>You asked about Googling HTML and CSS and "from scratch."  I fear you may have seriously misunderstood what I mean by "from scratch." </p>
    
    <p>Before revisiting "from scratch," I'll separate what I do and do not recommend:     
    </p>

    <h4>DO</h4>
    <ul>
        <li>Use Google and any other examples / sources you can get your hands on.  "Program by Google" is fine as long as you eventually understand the core code 
            you're using.  Again, start anywhere / however you want / however you can / whatever makes progress.  Do something--anything--to start.  </li>
        <li>Use others' code for specific tasks such as PHPMailer for email.  You do NOT have to understand its internals at all.</li>
        <li>Start with others' code as the entirety of your app, as long as you eventually understand the core logic.</li>
        <li>If you see something using Bootstrap CSS, find out what Bootstrap is doing and use that specific part without installing a zillion bytes of Bootstrap</li>
     </ul>
    
    <h4>do NOT, at least at first</h4>
    <ul>
        <li>use Angular, React, Bootstrap (CSS or JS), WordPress, Drupal, or the like</li>
    </ul>
    
    <p>When I say "from scratch," in part I mean use out-of-the-box JavaScript as opposed to a general library like React or Angular or even jQuery, at least to start.  
        You should know how to use basic JavaScript.  After gaining some understanding, perhaps in a month or two or so, then by all means experiment, probably starting
        with React.  For now, for my own purposes, I have turned away from all of the above including React.  I still want to whittle on my own JavaScript.  At this rate
        it will be 6 months at least before I reconsider that.  I put React highest on the list because I have not tried it and have heard good things.  I have tried 
        Angular and I found it to be a waste of time in the short-term.  It took longer to learn the "Angular way" than it would have taken me to do it myself and 
        even create my own portions of a library.
    </p>
    
    <p>The same applies to using WordPress and Drupal and such in PHP.  They fundamentally alter the dev landscape.  Using WordPress in some cases may be a 
        necessary evil, but you should still know how to do various things yourself.
        
    </p>
    
    <p>You're going to be Googling HTML and CSS and many other things for your entire career (or at least until Google is renamed after being seized for crimes against 
        humanity).  Starting with "program by Google" is fine as long as you eventually understand enough to modify it.  The long-term problem with "program by 
        Google" is people who do that and barely make it work and then have no idea what to do when it stops working.
    </p>
    
    <p>I need to fully distinguish PHPMailer from Angular.  Angular fundamentally changes how you do things.  Angular is a very general library that does a lot 
        of stuff.  Again, if you're going down that route, you should know 
        how to do basic things in pure JavaScript first.  PHPMailer does something very specific; it does not alter the entire dev landscape.  You don't have to 
        understand the internals of everything you use, or you'd never get anything done.
    </p>

    <p>Perhaps another way to come at it is that Angular is an overlay with which you do general dev.  It's an overlay of pure JavaScript.  You should know the basics of 
        pure JavaScript first.  You should be able to implement basic logic in pure JavaScript first.  
        PHPMailer is an overlay of SMTP, but it does a very specific task.  There is no reason for you to implement anything that specific.  
        If you implemented everything yourself, you'd never get anything done.  
    </p>
    
    <p>Another way: your current goal is to write a web form and get email notification of the entry.  You should understand a basic web form and be able to 
        modify it yourself, even if you copied the code.  You should have fluid control over your core product--the web form.  A web form is very general and 
        can have many field and do many things.  PHPMailer sends emails.  If it "just works," great.  It's not the core of what you're doing.
        
    </p>
    
    <p>Ideally, "from scratch" means you typed all the core code yourself, or you copied it from yourself.  You may be typing it yourself but looking every 
        single detail up.  The next nuance that is good enough is that you 
        copied it from someone else but you come to understand it well enough to modify it.  Then the next time you are copying from yourself.
    </p>
    
    <p>Going back to the Bootstrap CSS example, one problem with importing the entire Bootstrap CSS is that it formats every p, div, li, tr, td, etc.  You wind up 
        trying to override it and otherwise fight it.  I addressed this roughly 2 - 3 weeks ago below when I talked about PHP date formats.  The entirety of 
        Bootstrap.css is huge.  I whittled down to what I wanted and it was a tiny fraction of the whole thing.
    </p>
    
    <p>Another way: all of the "bad guys" above are very general libaries or systems or whatever that put a layer between your code and the fundamental code 
        below it--whether that's PHP, JS, CSS, HMTL, or whatnot. You don't want to distort your dev environment like that until you at least know what a pure 
        environment looks like.  
    </p>
   
</section>

    <section>
        <h3>January 11 - 12, 2022 - sending email "programmatically" (maybe done at 01:39 Jan 12, my time, UTC -5 / New York / Atlanta)</h3>

        <p>Continuing again with my web dev Q&A...  </p>
        
        <p>One lesson is that I realized below that my stack trace in the kwas() example revealed my username by way of revealing its path.  I removed that part, 
            but it's a lesson in security.  Knowing my username should not matter too much, for a number of reasons, but there is no reason to reveal it, either.
            It's good to consider such things for cases in which it does matter.
            
        </p>
        
        <p>As of the Jan 12, 00:27 version, I have reworked this somewhat since anyone last saw it. For one, I moved the section 
            on email providers up above the details of the PHPMailer class.
        </p>
        
        <p>My first comment goes back several entries, including an indirect reference in my Jan 9 entry: DO NOT CLOSE PHP TAGS UNLESS THE CONTEXT DEMANDS IT!  
           I will try not to boldface and put that in red, but we'll see what happens.  Just after your mail(...) function, you close the php tag.  In your code 
           snippet, there is no HTML or hint thereof, so there is no need to close the PHP tag.         
            
        </p>
        
        <p>Regarding the mail() function, what is the date on that code snippet?  Using the mail() function has become more and more problematic over the last 
            several years.  I hope no one is posting that recently.
            
        </p>
            
        <p>As for the gory details of the <a href='https://www.php.net/manual/en/function.mail.php'>mail(...)</a> function: as I read the documentation, I'm somewhat 
            surprised that I 
            have to read quite a bit before getting a hint as to your problem.  I know what you're problem is, more or less, but I'm looking at it as if I didn't.  
        </p>
        
        <p>To take the problem in parts: this is a case where kwas() would help.  Also, I mentioned that you usually want to be able to run code in CLI mode for 
            debugging purposes.  There is what happens when I use kwas() in CLI mode, and something similar would happen in "web" mode and kwas().
        </p>
        <p>First, the code, then running the script, below, and here is an active link of the following: 
            <a href='https://github.com/kwynncom/kwynn-php-general-utils'>
                     https://github.com/kwynncom/kwynn-php-general-utils</a></p>
        <pre>
&lt;?php
require_once('/opt/kwynn/kwutils.php'); // a clone of https://github.com/kwynncom/kwynn-php-general-utils
// kwas() is current defined on line 50, but that of course is subject to change
kwas($res = mail('bob@example.com', 'testing', 'test'), 'mail() failed - Kwynn demo 2022/01/11 21:58 EST / GMT -5');
exit(0); // I am simply emphasizing that this is the end of the code -- do NOT close the PHP tag!!!!
        </pre>
        <p>Running the script--the same thing happens in NetBeans CLI in the Output / Run window:</p>
        <pre>
$ php mail.php
sh: 1: /usr/sbin/sendmail: not found
PHP Fatal error:  Uncaught Exception: mail() failed - Kwynn demo 2022/01/11 21:58 EST / GMT -5 in /opt/kwynn/kwutils.php:51
Stack trace:
#0 [...] mail.php(4): kwas()
#1 {main}
  thrown in /opt/kwynn/kwutils.php on line 51        </pre>
        
        <p>I'll come back to this.  It occurred to me that nothing says you have to use kwutils in its entirety.  There is an argument for using your own 
            equivalent step by step as you understand the consequences.  The two points that I want to emphasize are kwas() and the two functions where I 
            change the error handling such that notices and warnings, and whatever else becomes an exception.  Those two functions are my own kw_error_handler() 
            (current line 69) and set_error_handler() which is a PHP function on line 77.  
        </p>
        <p>Back to the error at hand, a related technique to "kwas()" would be to note that the mail() function returned false.  You'd have to assign a variable to 
            the return value to see that, though:
        </p>
        
        <pre>&lt;?php
$mailResult =  mail('bob@example.com', 'testing', 'test');
if (!$mailResult) die('mail() fail'); // kwas() does the same thing with less lines, vars, and chars :)     </pre>
        
        <p>Also, in web mode, /var/log/apache2/error.log does show the error: "sh: 1: /usr/sbin/sendmail: not found"
                    </p>

    <p>You mentioned PostFix.  It may or may not install sendmail. I don't remember PostFix' relationship to sendmail.  With email, there is 
        both incoming and outgoing.  Even if you got sendmail installed, though, then there is the matter of configuring it.  I'm not sure 
        I ever got that working right.  I got incoming sort of working, years ago.  

    </p>
    
    <p>Even if you got sendmail working and the email got farther in the process, you have another big problem or several related ones.  When you use sendmail, it is 
        going to (try to) connect to the 
        server of the domain name of the recipient as specified in the MX DNS entry of the domain name.  Let's say that's gmail.com.  GMail may not accept the 
        connection at all.  Years ago, sendmail 
        would have worked fine, but then spam came along, and then SSL came along.  And then domain name keys came along, and related stuff around email and validating
        email.  Even if GMail actually accepted the email, it would send it to the recipient's spam box unless you did a LOT of work.  The work would involve DKIM and
        whitelisting and God knows what these days.
        
    </p>
        
    
    <p>So the mail() / sendmail path is a very steep uphill battle.  I've never tried fighting it very far.  I have also been bitten by this exact problem in a real, paid 
        project.  It 
        took until roughly 2 years ago to start causing bigger and bigger problems to the point of total failure.  Before that, there were spam problems.
        
    </p>
    
    <p>Far be it for me to call something like getting sendmail working a Quixotic quest.  I have made some motions to that effect.  However, in terms of an actual 
        real-world solution, even I have ruled it Quixotic.         
    </p>
    
    <p>I have used 3 solutions in the real world.  All of them involve the PHPMailer class that I address further below.  First, though, you have to decide on an 
        email sending provider, unless you want to fight the aforementioned uphill battle.
        
    </p>
 
       <h4>email service provider (sending email)</h4>
       
       <p>As I rework this, I realize that all this is just sending email.  That is your immediate problem.  I'm not even going to address receiving because I'm 
           not happy with my solutions.
           
       </p>
   
   
   <p>I said that I have used 3 solutions, all involving PHPMailer.  I do NOT recommend this first one, but I want to address it because it shows you 
       historically how things have gone along different paths, and it gives you basic info before getting somewhat more complicated.
        </p>
        
    <p>If you wanted to use GMail to send, there is at least one hoop to jump through even with the not recommended path.  If you want to do it the 2010 way, you have to 
        change a setting in your <a href='https://myaccount.google.com/security'>overarching Google account</a>.  (I thought you had to specifically turn on SMTP, but 
        perhaps not.  I am probably 
        thinking of IMAP and not SMTP.)  You have to set your overarching Google account's security allow "Less secure app access." 
        With this option, you would do that to avoid the infamous OAUTH2.  I'll leave it at that short sketch because I don't recommend it anyhow, for several reasons.  
        
    </p>
    
    <p>I used that above option in the real world until several months ago.  One problem is that Google will eventually and intermittently cancel the "allow" option.  
        It's just not a viable 
        option anymore.  The next option, which I still don't recommend, is to use GMail with the infamous OAUTH2.  I started doing that a few months ago when I 
        stopped using option 1, so I am currently doing it.  There are a variety of problems using OAUTH(2), however.  I'll mention it as a possible option and then 
        skitter away from it because it's a pain.  I have a specific reason for using it right now, but I'm still on the fence as to the cost-benefit.  In your case, 
        I would strongly consider option 3:
    </p>
    
    <p>Here I will propose something that may be mildly surprising or very surprising.  I like both free as in speech and beer, but in this case I'm going to 
        recommend a paid option, although it's almost literally dirt cheap for our purposes.  
        </p>
        
        <p>Yes, it's tempting to use Big Evil Goo for free as in beer (where you and your data are the product - TANSTAAFL), but it is a pain.  I would probably step 
            you through it if you 
            really wanted to, but it borders on Quixotic even for me.
            
        </p>
        
        <p>So I use AWS' Simple Email Service (SES), even for my own, non-paid-project notifications.  The cost is so low that I don't think I've actually paid a cent 
            for it even though 
            I use it with a paid project.  The project emails ~4MB files that add to the very, very low cost calculation.  The price is something like 
            1 cent per 100 emails or maybe even 1,000 emails plus 1 cent per 100 MB of size, or something like that.  
        </p>
        
        <p>For purposes of being thorough from a tech point of view, MailChimp Mandrill is an equivalent service.  I am almost certain MailChimp has gotten into the 
            deplatforming / censorship game, though, so I don't recommend them on that basis.  I did some testing with Mandrill years ago when it was free, but I also 
            can't recommend it beyond roughly 6 - 7 years ago because I haven't used it since.
            
        </p>
        
        <p>SendGrid is another alternative.  I would not say I have used it so much as I have seen it used, but that was over 3 years ago.        
        </p>
        
        <p>Getting back to AWS SES, I need to add another few steps.  You create a user in the SES screen.  That user includes the username and 
            password that you'll use in PHPMailer.  Note that the user you create in the SMTP screen is an IAM user, but you do NOT want to interact with that user 
            in the IAM screen, as I further address below.</p>
            
        <p>Also note that the PHPMailer username is not the IAM user with dots in it (by default).  The email PHPMailer username is of the form AKIA3ZN... 
            continuing
            with several more uppercase and numbers.  As the instructions tell you, you only get to see the password or download it once upon creation.  Otherwise 
            you have to create a 
            new user, which is no big deal, but just to save you frustration.  Note that I have found that renewing 
            the credentials of an SES user in the IAM screen does not work.  If you want to change the password, just create a new user in the SES screen and change 
            both the username and password.  If you change just the IAM password, you get silent failure.  That is, you get silence at first glance.  I never even set 
            the debugger on it to see 
            when or if the "silence" ends.  I just went back to the SES screen rather than the IAM screen.
            
        </p>
        
        <p>Another small potential problem with AWS SES is that you STILL have an issue emailing to arbitrary users--yet another layer of spam protection.  By default, 
            when you start using AWS SES you are in "sandbox" mode.  In sandbox mode, you send a potential recipient an email from an SES screen, and he clicks an 
            activate link.  THEN you can email that address.
        </p>

        <p>The SES screens list the port number and SMTP server and SSL / TLS / whatever settings, too, and they are in my code I mention below.  Once you have a 
            username and password
            and approved recipient, you're getting yet closer to actually, like, SENDING AN EMAIL.  Amazing, huh?
            
        </p>
    
        <h4>PHPMailer class and composer</h4>
    <p>All of my solutions involve the PHPMailer class.  I install it with the "composer" command.  "composer" itself is mildly irritating to install, as I remember.  
        You 
        can start with "$ sudo apt install composer" but I'm not sure it's going to work.  This is one of the roughly 20% - 30% of cases where "apt" / Aptitude is 
        either not the entire solution or the recent-enough package just doesn't exist for Ubuntu / Debian.  See what happens.  This is a case where I can probably 
        help quite a bit.  Yes, the solutions are of course out there, but I still remember that it was irritating.
    </p>
    
    <p>Composer is a tool specific to PHP.  It's a package management system for PHP (source code) libraries.
        When you install a composer library, by somewhat circuitous steps it's a 
        series of includes / requires / 
        require_once() that pulls the PHP source code into your own code.  That means that you can debug a composer-installed library.  I don't think I've had to 
        fix a bug in a composer library, but I have debugged into several of them in order to understand a problem and / or learn about how the library works.
        
    </p>
    
    <p>As an aside, I specified that composer installs libraries that are included and can be debugged.  That's as opposed to a library / extension that adds native 
        PHP functions.  For example, <a href='https://github.com/kwynncom/nano-php-extension'>my nano extention</a> is a PHP extension 
        written in C that creates a few native PHP functions.  Once it's installed, you simply call "nanotime()" like any other PHP function with 
        no include / require / require_once needed.  You cannot debug nanotime() just like you can't directly debug mail() by stepping into it.
    </p>
        
    <p>Getting back to your original problem, first you have to get composer installed. Then you need to decide where to put composer libraries.  I use /opt/composer
        I had to create the "composer" directory.  Then note that composer wants you using a standard user, NOT root or sudo.  Therefore, going back to your 
        lesson on permissions, I recommend changing "composer" to be owned by your own user and give 755 permissions (rwxr-xr-x).  The world / "other" users need to be 
        able to read and pass through.  There is no security issue with reading because the composer libraries are "public" code in the same sense that the "ls" command 
        is public.  
    </p>
        
    <p>Once you have your permissions right, do the following.  In my case, it's already installed, so your results will be different:</p>
    
    <pre>/opt/composer$ composer require PHPMailer/PHPMailer
Using version ^6.5 for phpmailer/phpmailer
./composer.json has been updated
Running composer update phpmailer/phpmailer
Loading composer repositories with package information
Updating dependencies
Nothing to modify in lock file
Installing dependencies from lock file (including require-dev)
Nothing to install, update or remove
Generating autoload files
5 packages you are using are looking for funding.
Use the `composer fund` command to find out more!  </pre>
        
    <p>Unfortunately, you're not quite done with your intro-to-composer experience.  After I just finished saying above that I wanted to emphasize 2 parts of kwutils, 
        I need to add a 3rd.  ("Our three main weapons are fear, surprise, ruthless efficiency...")  Once again, you don't have to use my kwutils, but you need to know 
        how to use composer.  If you go grubbing (grep'ing) around in kwutils, you'll see I do it like this...  Actually, this brings up an interesting question for 
        you.  
        If you use the whole kwutils, I think PHPMailer will "just work" once you have it installed under /opt/composer.  Let's see...    </p>
    
    <pre>&lt;?php
require_once('/opt/kwynn/kwutils.php');
kwas(class_exists('PHPMailer\PHPMailer\PHPMailer'), 'class does not exist');
echo('OK' . "\n");</pre>
    
    <p>Yes, it just works.  If you think that the 'PHPMailer\PHPMailer\PHPMailer' syntax is one of the weirdest things you've ever seen, I agree.  It gets into 
        PHP "namespaces."  I understand the concept, but I have barely studied them and have barely attempted to ever actually use them for my own code.  One of the 
        lessons I like to convey to apprentices is that I am very far from all-knowing, even when I should be a PHP "expert."  
   </p>
   
   <p>There may be "gotchas" just with require_once'ing kwutils.  Maybe you'll find out.  Either way, you should still understand what's going on behind the scenes:
           
   </p>
   <pre>&lt;?php
set_include_path(get_include_path() . PATH_SEPARATOR . '/opt/composer');
require_once('vendor/autoload.php');
if (!class_exists('PHPMailer\PHPMailer\PHPMailer')) die('class does not exist');
echo('OK' . "\n");   </pre>
   
   <p>That works.  As for actually USING PHPMailer, that is yet another step.  Isn't this fun!?!  Actually, in terms of something that should be simple like sending 
       email, this is one of the harder tasks I've had over the years.  Be happy that you're learning from my experience.  :)
   </p>
   
   <p>So, with that said, here is another decision point.  I have created 
       <a href='https://github.com/kwynncom/kwynn-php-general-utils/blob/6f3675f69158cc29a95bfb7d251cb9effe4feb0d/email.php'>my own email class</a> to use PHPMailer.  
       There are most certainly "gotchas" on that--that is, if you use my class precisely, you have to set up the credentials like I did, and there are probably 
       other gotchas.  Hopefully I give 
       instructions.  (It's been long enough that I don't remember.)  And if you want to do it "your way," that's fine, too.  Also, I just created a 
       <a href='https://github.com/kwynncom/web-form-message'>web form with email notification</a> a few days ago.  Yours does not have to be that complicated.  You can 
       just use an HTML "form" for now.  I get all fussy about save-on-edit (AJAX) because it was a specification of my main client.  It was a lot of work to 
       implement such that I'm still perfecting it. 
   </p>
   
   <p>Actually, to digress again, the save-on-edit went in 2 phases (so far).  For the most part, I got it working several years ago and that is still working.  Months 
       after one of my revisions, we learned the hard way that my solution lost way too much data in some cases.  I never did figure out what the "cases" were; I just 
       reconceived and rewrote part of it.  
       This problem wasn't catastrophic but it was of course annoying.  I rewrote the one field that was causing problems.  Since then, it has worked to the point 
       that my client hasn't reported any more problems.  I have reason to believe that small bits of data are still being distorted, but it's obviously not critical.  
       Obvious because nothing bad has happened in a long while.
       
   </p>
   <p>Because I got tripped up over that, I've kept whittling on my save-on-edit technique.  I will probably rework it yet again with my main client in the next few 
       weeks, as I partially rewrite the whole application to escape from Drupal and be compliant with PHP 8.0.
   </p>
   
   <p>Back to your email problem.  As for PHPMailer, you have my examples, and there are plenty more examples out there.  I'm going to try to wind this down.</p>
   
   <p>
       ALL THAT is to say that email is no longer easy because of nearly 30 years of spam wars.       
   </p>
    
    </section>
  

    <section id='id202209'>
        <h3>January 9</h3>
        
        <p>Cue Rage After Storm's "*autistic screeching*" that I address at some length in 
            <a href='/t/21/12/personal_blog.html#id202208'>my new personal blog</a>.  Several days or perhaps a few weeks ago I address 
            php tags and the infamous output before headers issue.  Now I can quote it precisely because I encountered it again, 
            "...cannot be changed after headers have already been sent."  I'm not sure that was the exact wording I saw many years ago, 
            but it's close, and it's the same problem.  In this case, the exact quote was 
            "ERROR: kwutils.php LINE: 201 - session_set_cookie_params(): Session cookie parameters cannot be changed after headers 
            have already been sent /opt/kwynn/kwutils.php"  For the record (again), /opt/kwynn is my clone of 
            <a href='https://github.com/kwynncom/kwynn-php-general-utils/blob/1a94eaccd6ec2578280984b3ff02de2d8f6afd67/kwutils.php'>my general PHP 
                utils file</a> and repo.  Note that the link is to a specific version of the file--the relevant one.

        </p>
        
        <p>I felt like "*autistic screeching*" when I saw that.  The good news is that now I know what to do.
            
        </p>
        
        <p>I'm going to get lazy and stop linking stuff.  You'll see changes in my GitHub in at least 2 repos in the near future.  
            I'm writing this 1/9 at 00:26 my time.  The short version is that you call a parent PHP file as the link target and then 
            require_once() the template.  The session stuff goes in the parent file before the template is called.
            
        </p>
        
    </section>
    
    
    <section>
    <h3>2022, January 5 (PM) - at least 2 entries</h3>
    
    <h4>"side exit" from the shopping cart (16:59)</h4>
    
    <p>Continuing again the web dev Q&A...</p>
    
    <p>The principle of "do something" includes taking "side exits."  It's fine to divert from the shopping cart to do something simpler 
        with a database.  Any understanding you gain is "doing something."         
    </p>
    
    
    
    <h4>MySQL became MariaDB...</h4>
    
    <p>...and "Istanbul was Constantinople."  </p>
    
    <p>I should have thought to mention this earlier.  If you take the relational route, MySQL became MariaDB.  For Ubuntu installation,
        I *think* all you need is sudo apt install mariadb-server <br/>
        In case it helps, I list what I have below.  The one command above should kick off the rest, though.  You'll need to download 
        MySQL Workbench directly from Oracle, though.  
    </p>
    
    <pre>   apt list --installed | grep -i maria
[...]
libdbd-mariadb-perl/impish,now 1.21-1ubuntu2 amd64 [installed,automatic]
libmariadb3/impish-updates,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 amd64 [installed,automatic]
mariadb-client-10.5/impish-updates,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 amd64 [installed,automatic]
mariadb-client-core-10.5/impish-updates,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 amd64 [installed,automatic]
mariadb-common/impish-updates,impish-updates,impish-security,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 all [installed,automatic]
mariadb-server-10.5/impish-updates,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 amd64 [installed,automatic]
mariadb-server-core-10.5/impish-updates,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 amd64 [installed,automatic]
mariadb-server/impish-updates,impish-updates,impish-security,impish-security,now 1:10.5.13-0ubuntu0.21.10.1 all [installed]  </pre>
    
    
    <p>To add to the confusion, MySQL is still being developed, as far as I know, but when Oracle bought the MySQL company, the open 
        source community forked MySQL into MariaDB.  When people speak of MySQL these days, they probably mean MariaDB in most cases, 
        or perhaps 85% of cases.
        
    </p>
 
</section>


    <h3>2022, January 4 - 5 (AM)</h3>

        
        <section>
        <h4>entry 2 on the 4th then into the 5th - sessions, etc. (into Jan 5 01:10)</h4>
        
        <p>Regarding sessions, my update to <a href='https://github.com/kwynncom/pizza'>my pizza code</a> gives an example.  I'm 
            only using a handful of function from /opt/kwynn, so you can either extract them or use my whole utility.  A reminder that 
            I addressed this at some length days ago.  Some of the usage in my little functions are very hard won information.  
        </p>
        
        <p>The session ID returned by my function keeps track of one user.  Behind the scenes, a cookie is going from 
            server to client and back.  Keeping track of the session is really that easy.  You can just call my "start" function 
            every time because if the sessions is already started, my function will return it.  Perhaps my function needs a better name, 
            in fact, or an alias.
        </p>
        
        <p>The cookie goes back and forth in the HTTP headers.  You can see both the headers in the network traffic and the stored 
            session on the client in Control-Shift-I as in India.
            
        </p>
        
        <p>The session ID is very helpful, but it's only a portion of the shopping cart code.  You addressed some of the rest of it 
            in your other questions.  I'll come back to them.
            
        </p>
        
        <p>You asked about echos within a PHP / HTML file.  In any entry roughly 10 days ago, I suggested up to 4 layers of PHP 
            code from back to front.  The echos go in the front most layer.  An example is my 
            <a href='https://github.com/kwynncom/web-server-access-log-analysis/blob/main/agents_sa/template.php'>user agent template 
                file</a>.  The variables are being build deeper and deeper and come out with the echo.
            
        </p>
        
        <p>More generally, a .php file can be all HTML, all PHP, or both.  If there is no php tag, then the HTML is going straight to 
            output--straight to the client / browser--from top to bottom as any other code.  When there is a php tag, that code is run, 
            and any HTML below isn't run until the php tag ends.  
            
        </p>
        
        <p>You can even do conditional logic on the HTML.  You can surround the HTML with { } of an if and conditionally output the 
            HTML.  I have an example of that somewhere.  Remind me to find it if you don't find one.
            
        </p>
        
        <p>Whether you can do the same thing in JavaScript is both simple and more complicated.  The short answer is yes, but if the 
            data is coming from the server, then it still has to get to JavaScript somehow.  But yes, you can do the same things in 
            PHP (server side) or JavaScript (client-side) with the cavaet that the data has to get to the JavaScript.  I discussed this 
            at some length "below" such as when I discuss using one big JSON rendered by JavaScript versus writing the HTML in PHP.
            
        </p>
        
        <p>How the client and server interact is a big question in that there are at least several good answers.  
            
        </p>
        
        
        <p>You mentioned clicks in JavaScript.  Yes, detecting clicks and what was clicked and what the click means more or less 
            has to be done in JavaScript, or at least it makes more sense.  You mentioned writing to a local JSON.  Note that 
            client side JavaScript can't write to an arbitrary local file.  JavaScript is very limited for security reasons.  There is 
            "local storage" in JavaScript, but I'm not sure there is a point in using it in this case because everything has to go to 
            the server anyhow.  
            
        </p>
        
        <p>As I mentioned several days ago, I tend to think you want to account for the user moving off the site and then coming back to 
            it, so the cart should primarily live on the server keyed by the session ID.  With some exceptions and alternatives, JavaScript
            data is lost when the user clicks away from the page.
            
        </p>
        
        <p>Getting back to the cart more generally, it's probably time to start learning about databases.  If you want to punt that, you can 
            save things to your own files or whatnot.  You are probably correct that the basic cart concept is harder than you 
            thought.  You'll have to learn about client-server interaction and databases, and that's before you do the payment / checkout.
            
        </p>
        
        <p>I should probably bang together the simplest shopping cart I can manage--perhaps 2 items with arbitrary quantities.  I assume
            you're done for the day, though.  I'm not sure I can be so inspired if you're going to bed.  Also, you might need to back 
            up and do some more general playing around with a database.  MongoDB would make my life easier.  I could live with MySQL, but 
            it would cause grumbling on my part.  Relational databases are so 1990s.  If you install MongoDB, I recommend Robo3T as a 
            GUI.  
        </p>
        
        <p>Yeah, as I think about it, learning basic database stuff and "hello world" both for the command line and programming databases 
            is probably going to be a detour for the shopping cart.  We'll probably do a lot of back and forth on this.  For now, I'm not 
            sure how helpful it would be for me to create a shopping cart.  
            
        </p>
        
        <h5>Need a database for the shopping cart?</h5>
        
        <p>Do you need a database for the shopping cart?  The short answer is very likely yes.  The longer answer is something I hinted 
            at above and you did in your email.  You mentioned the shopping cart as a JSON file.  Yes, the 
            cart can be a JSON file.  It's somewhere between impractical and 
            not particularly sensible to save that JSON file on the client side, but you could save it on the server side.  
         </p>
         
         <p>You could do something like that during development, but it's probably time to bite the bullet and learn databases.  
             For one of many examples, if you had a bunch of shopping cart files, it's harder to answer the simple question of "How many 
             orders need to be fulfilled right now?"  As its name implies, the purpose of a database is to organize data.  
         </p>
         
         <h5>which database?</h5>
         
         <p>MySQL is not installed on Kwynn.com.  MongoDB most certainly is.  I only have MySQL installed on my latest local system 
             because I could not quite justify moving my main (but part-time) client off of it until a few weeks ago.  Now I am 
             moving him off of it, but that's in the present tense.  I will be happy when I can delete MySQL from my system.  
         </p>
         
         <p>Part of my pitch for Mongo is that you've mentioned a JSON file, and that is one lovely thing about Mongo--you esentially 
             toss JSON files right in the database.  To get it into MySQL in a logical format is a lot more work.  
         </p>
         
         <p>With that said, you pointed out that all the PHP examples you've seen so far are MySQL.  MongoDB works in PHP just fine, but 
             I very likely am in a (small?  tiny?) minority of PHP users.  I assume the common PHP stack is still LAMP (Linux Apache MySQL 
             PHP).  Mongo 
             shows up in 
             the MEAN and MERN stacks (MongoDB, Express, Angular / React, Node.js), to name a couple.  
         </p>
         
         <p>On one hand, I leave it as an exercise to the apprentice to research trends in relational versus OO DBs.  On the other hand, 
             I can be reasonably sure that MySQL in particular isn't going anywhere anytime soon.  There may or may not be a slight trend 
             towards OO, but it must be slight at best.
         </p>
         
         <p>This is yet another instance of "do something."  There will be grumbling from me over MySQL, but just your point 
             about examples is an argument for starting in that direction.  (All of my GitHub code is MongoDB, but my code was not 
             written as a tutorial.)  Also, I might drop support for MySQL when I drop / delete 
             the whole thing, but that may be months away.  Right now I won't even bother with an estimate beyond "months."  
         </p>
         
         <p>On the other hand, just in the last few days I've started writing some of my Mongo code to be executed from the MongoDB 
             command line starting from PHP.  In other words, if you could find good lessons on Mongo, the first concern would be 
             learning it generally 
             from the prompt or better yet from Robo3T.  If you can learn it generally, running it from PHP is almost identical to 
             running it from Robo3T, now that I have libraries that do that more and more easily.
         </p>
         
         <p>I'll stop there and see what you come up with.</p>
        
        </section>
        
        <h4>entry 1 - responsiveness</h4>
        
        <p>Continuing the Q&A with my apprentice, today regarding "responsiveness" and such:
            
        </p>
        
        <p>I mentioned the JS and CSS refresh issue "below."  To recap, several options: you may have to put the code you're actively 
            working on in the 
            HTML file.  Then a refresh should work.  Remember that your CSS and JS files can be blank or commented out, waiting in the 
            wings for the cut and paste back to them.
            
        </p>
        
        <p>
            If you give the site a unique URL query http://localhost/?blah=1, then ?blah=2, etc., it might help.  Also, Firefox will 
            emulate a 
            mobile view to a large degree.  When you hit Control - Shift - I (as in India), there is a screen resizing icon on the right 
            middle / at the top of the dev tools screen.
            
        </p>
        
        <p>I'm sure there are other ways to solve the JS / CSS refresh issue.
            
        </p>
        
        <p>Also, you may be misunderstanding the point of "responsiveness."  Ideally the exact same CSS works for both.  Ideally it's not 
            a matter of detecting the type of device but writing fully dual-use code.  For example, tiles in a grid will settle to 2 rows of 
            10 columns on a big screen, but will be one column on a small screen.  A small number of the tools I use all the time are 
            specifically meant for mobile.  For that, I live with cartoonishly large text on a desktop.  Keep in mind sizing by vw and 
            vh--viewport width and height where 100 is full screen in that direction, but you do NOT use the percent sign.  You can of 
            course use the percent sign on other contexts.  I may use a font size of something like 3vw so that the screen could 
            hold roughly 33 characters width-wise.  
            
        </p>
        
        <p>With that said, there are probably times when you break down and use the CSS "@media" rule and / or detect dimensions in pixels 
            or such.  
            
        </p>
        
        <p>I'm sure lots of text has been written on this topic.  I am probably not the one to ask for much more, although I may find such 
            issues interesting enough to dig at with you.
            
        </p>
        </section>
        <h3>2022, January 2</h3>
        
        <p>First, an update to my previous entry:  For a week or so there was some DARPA LifeLog (Facebook) activity around 
            <a href='https://kwynn.com/t/9/12/sync/'>my very accurate clock web app</a>.  Then on the 30th it seems my clock was mentioned in a YouTube video and / or 
            its live chat.  
            I haven't tried very hard to track this down, but so far I have no idea of any more details.  Apparently I hadn't updated my web logs locally when 
            I wrote that blog entry on the 30th.  I thought I had.  Anyhow, it looks like somewhat over 100 people were playing with my clock roughly mid-day on the 
            30th my time.
            I have some indication that some came back the next day to count down New Year's in Australia--based on time and a few IP addresses I looked up.
        </p>
        
        <p>With that, back to the dialog with my apprentice:</p>
        
        <p>Even if you did use NetBeans, it would probably work with Java 11.  Given that you're not using NetBeans, no, there is no need to mess with Java in any way.
        </p>
        
        <p>As for <a href='https://github.com/kwynncom/kwynn-php-general-utils'>my utilities</a> that I clone as /opt/kwynn: just as with anything else, I don't see a 
            big reason to "activate" / require_once / include them until you need them.  You may need them soon, but 
            we'll cross that when we come to it.  I will offer two caveats, though, which should also re-emphasize two things I said a few entries ago:
        </p>
        
        <p>When you're in CLI mode, sometimes you'll see PHP warnings from stderr that NetBeans colors in red.  You may see them in web mode / HTML, too.  As I mentioned, 
            I changed my handler to kw_error_handler(), and it treats notices and warnings just like errors.  After doing this for over a year on my own projects, 
            I am sure it's the right answer.  I couldn't do it in Drupal because it was throwing way too many warnings.  Now I am doing it in the new version of my 
            steady (but always part-time) paid project, so it will get battle tested more and more.  
        </p>
        
        <p>Perhaps this is too subtle a point for the moment.  Also, I suspect PHP 8 does this to a degree--treats more issues as errors rather than a notice or 
            warning.  When and if you encounter not-quite-errors, though, keep this in mind.
            
        </p>
        
        <p>Also, I have never regretted kwas() all over the place, and that has been battle tested with my paid project.  kwas() lets you easily check your assumptions.  
            The first argument is either truthy or else an exception is thrown with the (optional) message in the 2nd argument and an optional error code that I had 
            forgotten about 
            until a moment ago when I looked at the function definition again.  Once again, this might be somewhat subtle, but you'll probably figure out how to use it 
            soon.
         </p>
     

    
    <section>
    <h3>2021, December 30 - web server log analysis - 3rd entry today</h3>
    
    <p>Below are 3 (or more) entries in my apprentice web dev "series."    </p>
    
    <p>In the last several weeks I have done more work on my <a href='https://github.com/kwynncom/web-server-access-log-analysis'>web server log 
            analysis</a>.
       I'm back to the question of how many human beings read my site, as opposed to robots?  Of those human beings, what do they read?       
    </p>
    
    <p>At least 79% of hits to this site identify themselves as robots.  See my "<a href='https://kwynn.com/t/21/12/ua/'>user agent</a>" page.  
    I don't have a definite number, but I would guess that of the remaining 21%, half of those are also bots that pretend to be a browser, although 
    the number may be higher. 
        
    </p>
    
    <p>Of THAT remainder, my own usage of my site is probably yet another half.  So my estimate is that 2 - 3% of hits are other humans.
        
    </p>
    
    <p>I can identify likely or definite robots in a number of ways.  Including my own robots (that have very legitimate purposes), devs rarely 
        update the fake user agent.  If an alleged browser version is over a year old, that's very likely a bot.  If it's 4 years old, which 
        I see all the time, that's almost certainly a bot.  
        
    </p>
    <p>At least one bot makes precisely 2 kinds of queries: to my home page and to non-existent pages.  It's almost certainly attempting to hack 
        my system by calling non-existent WordPress pages and such.
        
    </p>
    
    <p>AWS scans my site to make sure it's up.  I can tell by the IP address ownership and because it only reads my home page.  
        
    </p>
    
    <p>A bot will fetch many HTML pages in a second.  Humans don't do that.
        
    </p>
    <p>I'm sure I'm missing a few.</p>
    
    <p>Of the likely humans, I seem to have some "engagement" in that they move from page to page, but not a whole lot of engagement.  In 
        11+ years of this incarnation of my site, something like 5 people have contacted me only based on the site.  
    </p>
    
    <p>This might all bring up the question of what's the purpose of having a site.  The first answer is that I use it all the time.  I have 
        a number of tools I wrote that I use all the time.  That's another topic, though.
        
    </p>
    
    <p>Myself aside, I would probably keep it up, but that's also another discussion, perhaps for later.
        
    </p>
    
    <p>Regarding human readers, recently I'm trying to figure the chance that my site will 
        solve <a href='/t/8/04/housing.html'>my housing problem</a>.  My jury is still out.  I'll have to do a number of (many) hours more 
        work to keep clarifying the log data, and meanwhile I should be room hunting by more direct means.
    </p>
    
    <p>There's always more to say on this topic.  Perhaps later.
        
    </p>
    
    
    </section>
    
    <h3>2021, December 23 - 30 - probably beyond - web dev Q&A</h3>
    
    <p>This is an ongoing Q&A with one of my apprentices.</p>
    
<section>
    <h4>December 30 (Thu)</h4>
    
    <h5>entry 3 - starting 21:59</h5>
    
    <p>Consider using the "section" tag when appropriate rather than div.  I have starting doing it here, although I'm not totally 
        consistent.  I am almost certain "section" is new in HTML5.  Note that every section needs an "h" or "hn" or "h1..7" header, so 
        that's one way you know when it's appropriate.  I am assuming section and div are otherwise identical in terms of their defaults, but 
        I am not at all sure.
        
    </p>
    
    
    <h5>entry 2 - starting 21:39</h5>
    
    <p>Upon thought, I decided to publicly answer another part of your email:
    </p>
    
    <p>To be honest, I have already forgotten the git features in NetBeans.  I've pushed code several times since I mentioned it, and didn't 
        even consider NetBeans.  Perhaps I'll manage to use it before 2021 is over, or perhaps not.
    </p>
    
    <p>Regarding styling, I guess I've become slightly more interested.  I'd have to think about that quite a bit.  Yes, there has been movement
        towards being slightly to somewhat more decorative, but I'd have to think about all the reasons why.
        
    </p>
    
    <p>When you say "phone viewing," I suspect you meant to use another word.  Do you mean talking on the phone twice, and offering to go live?  
        That's a 
        long discussion.  I really should publicly explain my issue with the phone in some detail.  Not now, though.
        
    </p>
        
      
    

    <h5>entry 1 - posted and announced just before and at 21:37 EST</h5>
    
    <p>Regarding your blog, it does validate, so that's a great start.  I had almost no idea how you did the 1 second color transition.  I 
        vaguely knew such things were relatively easy, but I didn't know details.  When I went to look at this color "thing," I ran into 
        another pet peeve.  

    </p>

    <p>Immediately upon load / refresh, your page is showing console errors--both JavaScript and HTTP.  Also, when you click on the main 
        text of either entry, there is another error.  

    </p>
    
    <p>For unknown reasons, Firefox if not all (relevant) browsers get excited about a lack of favicon.  Just toss mine or anything 
        else in there for now.  Just make the errors go away!

    </p>


    <p>You may already know more than I do, but did you research the "-moz", "-webkit" and "-ms" properties?  My understanding is that's for very 
        old, 
        non-compliant browsers.  It may also be for very new features, though.  I'm not sure what happened with all that.  If it works on 
        both your desktop and phone, I'd call it a win and not clutter your CSS with such things.
        
    </p>
    
    <p>I am rewriting this part because before making such a fuss I should justify it.  I know that by HTML 4.01 if not long before, styling had 
        been removed from HTML itself as in HTML tags.  That is, the "font" tag was gone and related tags.  Therefore, I suspect that the 
        "emsp" / tab HTML entity is frowned upon by HTML5 purists for the same reason.  By using the tab, you are bringing styling into the HTML 
        itself rather than as styling.  I think you can use padding-left, and there likely other alternatives.  I'm almost sure I've seen your 
        spacing issue addressed by CSS.
     </p>
    
    <p>Rather than projecting upon others, I will declare myself an HTML5 purist and frown upon it myself.  In fact, for the first time ever I 
        will use the HTML frown code.  It seems appropriate to use it to frown at another code: <span style='background: yellow; '>&#9785;</span>  
        I will even style it!  There.  You have been frowned upon. </p>
    
    <p>Yes, that is an appropriate use of the style attribute rather than "class."  
        
    </p>
    
    <p>Back to whitespace, don't forget the "pre" HTML tag.  There are cases where you don't want the default rules of HTML messing with your 
        whitespace, and "pre" is one of the solutions to that.  I use it just below and elsewhere in this page.  (It's also useful when 
        outputting numerology values and making them line up with the letters.)
        
    </p>
    
    <p>Also, I would add the year and timezones to your blog.  They don't have to be in the header, just somewhere.  Hopefully those entries 
        will be online for many years.  
    </p>

    <p>On that note, you may have noticed that my websites suffers from a variant of the Y2K issue.  I started this incarnation of my site 
        in 2010.  I remember thinking about it at the time and deciding that my life would almost certainly be very different by 2020.  
        Certainly I would not be pecking away at the same file hierarchy.  The joke is on me.  With that failed assumption, in URLs I numbered 
        the years 0 for 2010, 1 for 2011, ..., 9 for 2019.  Then I had to use 20 and 21 and very soon 22.  This of course throws off 
        the ordering of digits:</p>
    <pre>/t$ ls
0  1  2  20  21  3  4  5  6  7  8  9</pre>
    <p>    THAT is annoying.  Just a cautionary tale.</p>
    
    <h5>caching revisited - especially CSS and JS</h5>
    <p>Firefox and possibly others can be very annoying when it comes to caching / refreshing external CSS and JS.  Often times I have given up and 
        put the JS and CSS back in the HTML page just long enough to get it to refresh.  I mentioned this several days ago that it may be 
        worth quite a bit of coding to check JS and CSS refresh.  I think you misunderstood what I meant because you had a file with the date in 
        it.  I meant using server-side code to get the filesystem date of all the files involved.  Then you'd have to modify the JS and CSS 
        on the server side 
        and then run JS to make sure the changes are made.  All of that is probably going too far.  Some much easier things that might work are:
    </p>
    
    <p>Click the JS / CSS link in the "view source" or debugger and hard refresh it.  Make sure that is refreshed.  Then hard refresh the HTML 
        page.  I think that almost always works.  Sometimes adding a (literally?) random URL query makes the browser think it's a different page, 
        and that works, such as 
        blah.html?refresh=1.  But then you sometimes have to keep incrementing the numbers. When you turn the cache off in Drupal, the query 
        becomes a UNIX Epoch timestamp for that reason.
    </p>
    
    <p>The situation on mobile can be so bad that you have to put JS and CSS that is under heavy dev in the HTML.  Remember that you can make 
        your page a .php rather than .html and simply "include" the styling.  For that matter, you can write PHP code to switch back and 
        forth between internal and external.
        
    </p>
    
    <p>Remember that you can see caching or lack in the network traffic.  I just refreshed your blog, and I had to do a hard refresh to 
        get the CSS to go over the network again.  I don't think it showed me explicitly that it was caching, it just didn't show the CSS 
        going over the network.  I think you can see the caching itself somewhere.
        
    </p>
    
    <h5>caching generally</h5>
    <p>I have suffered many issues over the years with caching in various contexts.  I have harsh words for developers who don't make it very easy 
        to definitively turn the cache off.  Furthermore, caching is way overused.  As 2022 approaches, if you can't make your process work in 
milliseconds without caching, there is probably something else wrong.          
    </p>
    
    <p>Firefox has a legitimate reason for caching because zillions of people use the browser and thus caching has saved an enormous amount 
        of CPU time and network traffic over decades.  However, Firefox should still have a way to definitively turn the cache off.  Maybe it 
        does, in fact.  I think I've looked, though, with no luck.
        
    </p>

    <h5>back to your blog</h5>
    
    <p>When you talk about text wrap, I think you misunderstand what the flex box does.  The flex box wraps entire divs.  Whether text wraps 
        is a separate issue.
        
    </p>

    <p>As for centering an image, I have very little advice.  Sometimes the "auto" value comes in handy for such things.
        
    </p>
</section>
    
    <section>
        <h4>December 28 - 2 entries</h4>
        
        <h5>8:55pm - starting to write</h5>
        
        <p>Note the previous entry, about an hour ago.        </p>
        
        <p>Do you need the cookies?  As I said yesterday, you do at least for the scenario of someone accidentally closing their window and coming back to 
            the site.  You may or may not need them other than that; it depends on how you arrange your page.
            
        </p>
        
        <p>How to implement them?  It's as easy as I laid out yesterday.  If you use my wrapper around the session functions, it's that easy.  If you don't 
            use my wrapper, see my caution about not restarting an existing session.
        </p>
        
        <p>If you're considering doing it "from scratch," I would advise against in this case.  Out-of-the-box PHP does the job splendidly.  This is a 
            case of "just use it."  If you want to do it yourself, I'd save that for months from now.  The short version is that the cookie goes out 
            in the HTTP response header and comes back in the request header.  There's no reason to mess with any of that now.  You will want to see the 
            cookie itself in control-shift-I storage.  
        </p>
        
        <p>As for an SSL cert, I very rarely bother with them on my dev machine.  My implementation of sessions allows the session to ignore SSL on my 
            dev machine and / or non-AWS machines.  My functions assume live is AWS.  I may have to deal with that at some point.
            
        </p>
        
        <p>If you want to do it, I recommend certbot by Let's Encrypt.  I installed it as a snap rather than an Ubuntu package.  You have to register a 
            cert against a domain name or subdomain, so you'll need to route such to your dev machine.
            
        </p>
        
        <h5>8:00pm (approximately)</h5>
        <p>We talked on the phone for a while.  I was giving a lesson and solving webadmin problems as I walked.  
            
        </p>
        
        <p>Today's phone lesson was in part about Apache DocumentRoot and setting directory permissions for the www-data user / group.  
            
        </p>
        
        <p>Some reminders from that lesson...  The path all the way from / to document root should have my recommended 710 permission and have www-data group 
            access.  Document root itself probably needs or should have 750 permission.  
            
        </p>
        
        <p>Considering changing everything else in ~ to 700 (dirs) or 600 (files).  There is a chmod X tag that does this quickly.  chmod can be used with 
            the bitmask or "letter" flags and pluses and minuses.  
            
        </p>
        
        <p>If you ever figure out how to change the default such that files and dirs don't get such wide permissions, let me know.
            
        </p>
        
        
        <p>Going back to the email exchange, he said he's going to try the JetBrains WebStorm IDE / debugger.  Apparently it's proprietary, but he has a 
            free-as-in-beer license from college.  (I of course use free as in beer and speech Apache NetBeans.)  This is a case where following Kwynn's Rule 
            #1 is more important than open source versus proprietary.  As long as he's using a debugger, I will try not to further comment.
        </p>
        
        <p>&gt; i'm going to hold off on using the integrated git vcs because i want to continue to learn the command line way of doing things and get familiar 
            with that.
        </p>
        
        <p>Agreed.  With that said, I've been vaguely noticing that NetBeans has this stuff.  Now that you mentioned it, I looked harder.  It hadn't gone 
            through my head that NetBeans has all the commands.  For the usual tasks add, commit, push, I think I've got that down at the command line well enough 
            that I may try out NetBeans' commands.
        </p>
        
        
        
    </section>
    
    <section>
        <h4>December 27</h4>
        
        <p>Starting from one of yesterday's emails, a flex box grid sounds good.  I have found it useful.  Perhaps some other time I'll do a 
            recursive search on my web tree and find all the instances where I use it.  I've considered giving you a copy of the site, in fact.
        </p>
        
        <p>To various questions from both yesterday and today about the shopping cart and client versus server side...  You'll probably want to 
            use PHP sessions, which is a cookie with a unique ID.  The PHP functions do it all for you, though, in terms of creating the id and managing 
            the cookie.  In <a href='https://github.com/kwynncom/kwynn-php-general-utils/blob/45539f41f62362281c32de1e4c7b0f3c04337a1a/kwutils.php'>kwutils.php</a>, 
            see startSSLSession().  This is at least one big "gotcha" that I solved with that function: the session functions get ornery if you start 
            a session when there is already a session.  In fact, doing so might lead to the horrible beast that goes to the effect of "output before [HTTP] headers."  Which
            reminds me:
            
        </p>
        
        <h5>the output-before-HTTP-headers issue and intentionally NOT closing PHP tags in most situations</h5>
        
        <p>The following is a counter-rule to every other situation in programming.  In all other cases I know of, if you open a tag you should close 
            it.
        <span style='font-weight: bold; font-size: 130%; color: red'>
            Do NOT close a PHP tag ?&gt; unless the context demands it!
        </span>  
            
        </p>
        
        <p>That is, unless the PHP is switching back and forth with raw HTML, you don't need to and <b>SHOULD NOT</b> close the PHP block / file.  
            Look at my code.  I am almost certain I am 100% consistent about this.  I would be surprised if you found a counterexample in my GitHub.
         </p>
         
         <p>The problem is when you have an included file in a mixed-PHP and raw-HTML file.  In the included file, if you close the PHP tag and then hit a newline 
             or even a space, 
             that is considered raw text and will be outputted because it's not PHP.  If it's an include file or otherwise outputted before the HTML 
             itself begins, you'll get the "output before [HTTP] header" error.  
          </p>
          
          <p>That error indirectly led me to quitting two projects around the same time, many years ago.  I spent a lot of time chasing that issue 
              around.  
              I think it took me months of calendar time to figure out what was causing it.  And the way it happens is insidious. It's like a 
              virus that seems to pop up at random.  Those projects may have gone on for quite some time or even indefinitely, so that little bitty 
              issue may have caused me an enormous amount of money.  That's not even the situation where violating (what is now) rule #1 cost me 
              even more, potentially.  I'll come back to that.
        </p>
        
        <h5>back to sessions</h5>
        
        <p>So, when using sessions, make sure to return the session_id() if it's truthy (sic) rather than trying to restart the session, as my function 
            shows.  Then that function calls another in the same file that forces SSL.  In your case, you'll (also) want to 
            do the standard Apache rewrite that forces SSL anyhow.  You'll want to do that because you're starting from scratch.  I am afraid to do it for 
            Kwynn.com 
            at this point.  It's on my agenda to thoroughly test it.  Perhaps I'm being paranoid, though.
        </p>
          
        <p>Once the session starts with session_start(), every time a PHP file is called from the 
            client, the session_id() will give you a long-enough unique string.  That will help with the shopping cart and otherwise keeping track of what 
            a specific user is doing.
            
        </p>
        
        <p>The PHP session functions create a cookie named PHPSESSID.  It's 26 characters.  I'd have to experiment to be sure, but it looks like a regex 
            of ^[a-z0-9]{26}$  So 36 to the 26th power is 10^40.  I think that'll suffice.  
            
        </p>
       
         
        <h5>server versus client calculations</h5>
        
        <p>As for whether to use the client or server for calculations, you MUST at least check the calculations on the server for reasons you 
            mentioned in one of your emails and I mentioned in the last few days in this blog.  That is, if you rely on client data, a malicious user 
            can change the price and thus total cost.
        </p>
        
        <p>With that said, it's a toss up whether to do the initial calculations on the client side or server side.  I tend to think it would be tedious to 
            do every calculation on the server and send it up and down.  It depends on several things.  
            
        </p>
        <p>"Where are the cart items stored?"  If you are using one HTML page, in theory you can store it only on the client side until checkout.  However, 
            you should allow them to close the page (perhaps accidentally) and come back to it with the same session ID.  (Sessions can last for years or 
            decades, in theory.)  Thus, the cart items should be sent to the server on each click and put in a database, keyed by session ID and perhaps 
            other keys depending on how you're arranging the data.  "Key" in this case means unique index or the fields that uniquely identify a row in 
            relational or a document in MongoDB (object oriented DB).  
         </p>
         <p>You spoke of an unordered list in JavaScirpt.  I have a few guesses what you mean, but I'm not sure.  You can keep the cart in JavaScript as a 
             global variable of the object type.  Generally speaking globals are frowned upon, but this is a reasonable use case for them.  The 
             MongoDB database entry can be the JS variable to a large degree, other than the Mongo version will have the session ID and perhaps some other 
             added fields.  Remember that if you go to a new page, you've wiped your JavaScript, so you'd especially need to make sure the server had the 
             cart by then.  (Again, the server should probably have it upon every click.)
         </p>
         <p>
             &gt; ["&gt;" indicating apprentice's words] the button executes Java script and that takes the data from their selections and stores it in a shoppingCartTotal

         </p>
         
         <p>Close.  Perhaps more like global variable object GL_RO_APIZZA_CART is the entire cart, with or without the total.  You may or may not 
             want to save the client side total in a variable as opposed to displaying the calculation each time.  That is, the number and type of each 
             items needs to be in the cart, but you don't need to keep track of the total in a variable.  
        This also goes to a larger issue of when you store data that can be calculated.  (I don't think I'll elborate on that for now.)  Which way to do it 
        will probably occur to you when the time comes.
             
         </p>
         
         <h5>abstraction</h5>
         <p>&gt;  - my mind is abstracting away a lot of the data but Im sticking to your principle of just getting something built. I can see how designing a 
             template based system would be appropriate if I wanted to expand further with the software and incorporate into other small businesses. 
             (Meaning making generic tiles that scan a database and pull in whatever data is there)
         </p>
         
         <p>You have the idea.  It's a tradeoff and a big question as to how much you want to abstract and when.  One of my issues with Drupal and WordPress 
             is that they have abstracted to the point they don't do anything specific well.  Decades ago a comedian said, "I went to 
             the general store, but I couldn't buy anything specific."  That is part of the problem with CMSs.  
         </p>
         
         <p>So yes, in theory you can have generic tiles and generic interactions and calculations.  It's hard to say how far you can take that before 
             it becomes too generic / general.
             
         </p>
             
         <h5>crypto</h5>
         
         <p>Yeah, maybe.  Sure.  I'd get Federal Reserve Notes working first.  (If anyone spends legal dollars at any pizza shop, anywhere, let me know.  
             Legal dollars are still <a href='https://catalog.usmint.gov/coins/precious-metal-coins/bullion-coins.html'>gold and silver minted</a> with 2021 
             stamps by the US Mint.  Paper and computer entries are at best fraudulent  
             promises to pay real dollars at some point in the infinite future.  The paper and computer bits represent private script created by the 
             banks against your mortgaged house and other such collateral.)  
             
         </p>
         
         <h5>corporations and legal protection</h5>

         <p>Note that I'm just an amateur legal hobbyist, so I can't give legal advice.  With that said:
             
         </p>
         
         <p>I am also currently judgment proof, so I'm not really one to talk, but with that said, I tend to think you're being paranoid.  If your system 
             accidentally charges someone $1,000, you return the money via the chargeback process, the same way a waitress would do at a restaurant.  
             When the system 
             first goes live, you should have access to the account for that purpose.  You should probably always have access to the account.  
         </p>
         
         <p>As for credit card numbers, you're not storing them.  The way PayPal and perhaps every other system can work is that the client pays on PayPal's 
             system and your system gets a "callback" when the money is approved.  You never see their credit card.  For that matter, you don't need their 
             real name, let alone their email.  You just need something to tag their order with when they come to pick it up.  This can be a small number if 
             you recycle them often.
         </p>
         
         <p>I'm curious if you can find cases of individuals or small companies being sued for bugs.  At this point it should be legally assumed that 
             software comes with no guarantees.  It is said that if buildings were built the way software is written, the first woodpecker would end 
             civilization.  One of my professors addressed that.  The comparison is simply not fair to us.  Builders can see and put their hands on 
             and test and inspect everything.  There is no such visibile equivalent in software.  We can only do our best within budget constraints.  
         </p>
         
         <p>Also, a not funny story along those lines.  One of my brief quasi-apprentices created the type of corporation that fines you $400 per shareholder 
             for filing taxes late.  The business made absolutely zero money, and he was already paying fines.  I howled laughing at that.  I told him it was 
             one of the best examples I'd ever seen of the cart before the horse, to which he (rather foolishly, as I'll explain) said that at least he had a 
             cart.  
         </p>
         

         
         <p>Especially in the context of his "cart," people seem to forget that corporations (including governments) are not real in that they are not at all 
             tangible. "The government" does not do anything, only people alleging to act for the government.  You don't need a corporation to write software.  
             You don't 
             need a "cart."  I've never incorporated and never seriously considered it.  There was a situation many years ago where having an artificial entity 
             tax ID  would have saved me about $1,000, but the 
             cost of creating and maintaining the entity probably would have approached that.  I have no regrets.
             
         </p>
         
         <p>That's a tax ID as opposed to a socialist insecurity number that refers to an equally artificial legal entity.
             
         </p>
         
         <p>You may decide that there is enough reason to incorporate or write a trust.  Trusts have the relevant legal protections of a corporation but don't 
             need to be blessed by the government for their existence.  If I 
             were to go that route, I would create a trust.
             
         </p>
         
         <p>One of my systems has processed something like $500k over several years in a somewhat different context.  I did the first $25,000 "by hand" 
             in that I processed each line item while watching it in the debugger (NetBeans) and stopping several times (breakpoints) for each item.  
             I also had 20 - 30 checks, maybe more, to confirm that I was on the right account and only entering what the client approved.  
             Yes, it was very nerve wracking at the beginning.  After all these years, though, my "interlocks" and cross checks and such have done their 
             job.  
         </p>
         
         <p>I've had a number of rather embarrassing bugs on much less critical parts of the system.  At one point I lost a reasonable amount of data, although 
             it was reproducible.  In a rare event, two data-corrupting bugs have shown up in the last 5 weeks or so.  One was likely a rather small amount of 
             data lost that is also reproducible.  The other might have caused some minor (moderate?) problems.  But this project has a limited budget; I can 
             only do 
             so much testing in the areas where big money isn't at stake.  With that said, I'd like to think I've learned something from 2 data-corrupting bugs 
             in 5 weeks.
          </p>
         
          <p>I know a good lawyer in your area, as we've discussed.  :)
              
          </p>
          
          <h5>back to debuggers</h5>
          
          <p>I started this blog page 4 years ago in order to state rule #1, so it's at the bottom of the page.  The quick version is "never dev without a debugger," as 
              defined briefly just below.
              
          </p>
          
          <p>Just to reiterate that Kwynn's rule #1 applies to both the client and server side.  A browser's debugging tools can't help you on the 
              server side.   A "debugger" means that you can step through the code 
              line by line, see where the code goes, and check the value of each variable at each point.  echo(), print(), printf(), console.log(), etc. 
              are not effective debugging tools.  They have very limited purposes, and sometimes you can get away with this, but failure to use a debugger 
              might literally have cost me $100,000s indirectly, so now the tale:
          </p>
            
          
          <h5>why I created rule #1 after the horse burned with the barn</h5>
        
          
          <p>This was years ago and the last time I tried working 9 - 5.  I was working in Ruby and thus didn't know of a debugger.  Quick searches didn't 
              turn up any free ones.  I don't remember if there were proprietary ones; in hindsight, $500 would have been worth it.  I tried debugging 
              with whatever Ruby's print() is.  In part because I was so tired, I kept chasing my tail.  Part of the problem was that they were using 
              Heroku or something of the sort, which I didn't fully understand.  The code was initiated from a worker process callback.  A debugger would have 
              brought that to light much faster.  I never did solve that bug before I got tired literally beyond reason and quit
          </p>
          
          <h5>back to debuggers, again</h5>
          <!-- **** -->
          <p>Writing code in gedit and going into NetBeans just for debugging is perfectly fine as long as you aren't hesitating to debug because you're 
              not already there.  Also, NetBeans is better at HTML decoration (such as coloration) than gedit. For one, gedit has a very obnoxious bug that 
              causes it to lose all the decoration when I do "h" tags.  I just tried it; that bug is still there.
          </p>
          
          <p>I'm not set on NetBeans as long as you use a debugger (more options below).  I have had good luck with it for many years, though.  It has a few 
              quirks, but I can live with them.  One quirk in 12.4:  it will not kill your code, either in PHP or C.  That is, you hit the kill / stop button, 
              and rather than dying, the code will go on to the end despite breakpoints.  That is somewhat annoying, but I've learned to live with it, too.  
              I may have to write around that, though, for some code.  Also, I have not looked into it; there may be a simple solution.
           </p>
           
           <p>Years ago I used Eclipse, and I brielfy used Eclipse last year.  It works.  I'm almost certain PHPStorm is proprietary, but in this case I'd 
               prefer you use proprietary software rather than not use a debugger.  I'm fairly sure there are other options.
  
           </p>
           
           <h5>back to client v. server and security</h5>
           
           <p>&gt;  which raises a question: can i keep all the data that im building on client side for the check out car and do all my calculations on client 
               side as well, then send those off to the payment processor? 
           </p>
           
           <p>Note that my apprentice had not seen the above before asking this.  To reiterate the above: you can do the calculations on the client side, but 
               you must also do it 
               once on the server side to check the paid amount.  
     
           </p>
           
           <p>&gt; i'm assuming it's bad to keep the prices client side
           </p>
           
           <p>It's fine to send prices to the client side as long as you check / confirm / recalc on the server side.  You only have to check once against 
               the payment on the server side.  It's probably easier to do it on both 
               sides.  It's tedious 
               to go back and forth with the server, so build the cart on the client side.  Then do it just once on the server side.
  
           </p>
           
           <p>One thing I didn't mention above is that this is a case for using Node.js as your server side language.  Then the exact same code can 
               calculate on both sides.
               You can use also Node from PHP in at least two ways.  In my generic logon / user identity system, I use the 
               <a href='https://github.com/kwynncom/generic-php-login/blob/032e137c02211f3ee965603cc38b7441d55d9bf0/js/dangerousChar_Node.js'>
                   exact same code</a> by calling 
                   <a href='https://github.com/kwynncom/generic-php-login/blob/032e137c02211f3ee965603cc38b7441d55d9bf0/charValidator.php'>Node as a shell script</a>.  
          </p>
          
          <p>I've invested so much time in PHP that this relatively small issue isn't a reason to go to Node.  It might be a reason for you to do so, though.
              I call it a small issue because it doesn't take long in any language to add up a total.  That is, it doesn't take me long.  What you're doing 
              is non-trivial for a beginner.  I'm sure you'll do some floundering.  
         </p>
         
         <p>I'm still decding on some of the basics of my own webdev.  Because certain projects involved Drupal, I didn't have full freedom.  Now that I do 
             have full freedom, I'm still working on the best way to do things.
             
         </p>
           
           <p>&gt; because someone could
essentially change the submission price manually on the cart resulting
in bad behavior.</p>
           
           <p>Correct. That is the sort of thing you're protecting against by confirming on the server side.</p>
           
           <p>More generally, any data sent from the client cannot be trusted and you have to consider all the mischief client data can do.  
               So there is SQL injection, injecting JavaScript (or links) into data that may be displayed on the web, and injecting large amounts of data just to 
               run your server out of space.  Those are just a few.  
            </p>
            
            <p>In the web contact form in progress in my GitHub right now, I check the format of the pageid.  I limit the number of characters.  I escape 
                the text when I display it on an HTML page.  In other cases, I make sure numbers are numbers.  I probably have not thought of everything 
                in that case, but the stakes are not particularly high.
            </p>
            
            <h5>modal</h5>
            
            <p>"Modal" is one of those terms that annoy me.  They make it sounds like some very special thing.  Is this a particular modal library, or is it 
                just an example?  How big is the library in bytes?    I'll come back to this.
           </p>
           <h5>a rant on bootstrap.css</h5>
           
           <p>The minimized version of bootstrap.css (v3.4.1) is 120kb.  The <a href='https://www.php.net/manual/en/datetime.format.php'>PHP date format</a>
               uses this.  I once decided I wanted <a href='https://kwynn.com/t/20/08/dates/phpdoc/doc.html'>my own copy</a> of the table.  I had a cow 
               when I found how big bootstrap.css was.  So I started with the "maximized" / dev version and 
               <a href='https://kwynn.com/t/20/08/dates/phpdoc/css/'>whittled down</a> what I wanted.  I count 3.4kb.  
           </p>
           
           <p>
              This also goes to the issue of being so general that it doesn't do anything specific well.  
               Drupal uses Bootstrap, which is one of many issues I have with Drupal.  I have elements' styling overridden by Bootstrap.  It's very annoying.
               
           </p>
           
           <h5>back to modal</h5>
           
           <p>Anyhow, "modal" sounds so special, but it's not hard to do yourself.  First of all, do you need anything of the sort?  Why not just a plus 
               and minus and a text number box for quantity?  As soon as they push that button, it goes into the shopping cart.  
           </p>
           
           <p>If you want a modal popup-like effect, you can use CSS z-index and fixed positioning.  z-index is a pain to use the first time if you 
               don't have the decoder ring, but it may be worth it in th end.  Here is the 
               <a href='https://kwynn.com/t/20/06/flag/pt2/index.php'>"flag" example</a>.  I thought I had another 
               example, but I'm not finding it with a recursive search (grep -R z-index).  The key, as I remember, is that the elements involved must 
               have a "position" attribute rather than the default static.  If this gets out of hand, let me know.  I'm sure there is another example.  
               Also, I have an example in a client's proprietary code.
               
           </p>
          
    </section>
    
    <section>
        <h4>December 25</h4>
        
        <section>
            <h5>debugging PHP</h5>
            
            <h6>a debugger</h6>
            <p>Remember that Kwynn's dev rule #1 is to the effect of "never dev without a debugger."  I use Apache NetBeans as the GUI of my PHP and C debugger.  
                Before NetBeans will install, though, you need both a JDK and JRE that I address below.
                I don't think NetBeans is in the Ubuntu package repositories anymore, so download it directly from Apache.  
                I'm using version 12.4. As best I remember, you download the file and then "sudo bash file.sh" to install it.
                You run bash because otherwise you have to turn the execute bit on, which you can do graphically and easily 
                via the command line, but just running bash should work, too.  You need sudo because it's going to install 
                stuff all over the file tree such as something close to if not precisely /usr/bin and /usr/lib and such.
           </p>
           
           <p>NetBeans needs a JRE and JDK.  Installation notes below.  I'm pretty sure I have used higher versions of such
               than the following, but these work, so might as well install what I have.  
               
           </p>
           
           <p>I'm going to list what I have and then explain how they relate to the install commands.  I'm going to 
           somewhat change the output to remove clutter.  There is some chance you'll already have something installed.  If so, 
           see if it works before messing around with different versions. </p>
           
           <pre>
apt list --installed | grep jdk

openjdk-8-jdk-headless/impish-updates,impish-security,now 8u312-b07-0ubuntu1~21.10 amd64 [installed,automatic]
openjdk-8-jdk/impish-updates,impish-security,now 8u312-b07-0ubuntu1~21.10 amd64 [installed]
openjdk-8-jre-headless/impish-updates,impish-security,now 8u312-b07-0ubuntu1~21.10 amd64 [installed,automatic]
openjdk-8-jre/impish-updates,impish-security,now 8u312-b07-0ubuntu1~21.10 amd64 [installed,automatic]
</pre>
           <p>You'll need to install those 4 packages, where the package itself corresponds to everything before the first /, such 
               as "sudo apt install openjdk-8-jre-headless"</p>
           
           <p>Eventually you'll need to install "php-xdebug"</p>
           
           <p>Then you'll need to make changes to both /etc/php/8.0/cli/php.ini and /etc/php/8.0/apache2/php.ini at the 
               very end of the file, or wherever you want; see just below.  I put my name in a command to indicate where I 
               started a change.
           </p>
           <pre>
; Kwynn
xdebug.mode=debug
xdebug.client_host=localhost
xdebug.client_port=9003
xdebug.idekey="netbeans-xdebug"
           </pre>
           
           <p>
                 Then restart apache (web server) for the apache-php changes to take effect:   sudo systemctl restart apache2
             
           </p>
           
           <p>Then "debug" a project inside NetBeans and you should get a green line in your code.  Beyond that, I should 
               give you a tour.  And / or see if you can find discussion of how to use the NetBeans - xdebug - PHP debugger.
           </p>
           
           <h6>kwutils - very strict notice handling and "kwas()"</h6>
             <p>You'll note that many of my files begin with require_once('/opt/kwynn/kwutils.php');  /opt/kwynn is a clone of 
               <a href='https://github.com/kwynncom/kwynn-php-general-utils'>my general PHP utilities</a>.   You'll have to 
               play with permissions to install it as /opt/kwynn.  You can also of course do it however you want, but /opt/kwynn
               is probably a good idea if you want to easily run my code.
               
           </p>
           
           <p>You and I should probably go over kwutils thoroughly some day and whittle on it.  It's gotten somewhat 
               cluttered, but I consider it professional grade in that I'm starting to use it in the new version of my 
               regular (but 5 hours a week) paid project.  Also, I've been using it on almost all my projects for about 18 months now.
           </p>
           
           <p>
               In the first few lines of kwutils.php, I change the error handler such that notices and warnings kill your 
               program just as thoroughly as a fatal error.  I have never regretted this decision.  It makes for better code.
               This may be less important in PHP 7 and 8, but I see no reason to change course.  I don't think this would 
               help much with your immediate bug, but it's relevant to debugging generally.
            </p>
            
            <p>Combined with advice below, what would help is my "kwas()" function.  It stands for "Kwynn assert," and I want 
                it to have a very short name so that I am encouraged to use it ALL THE TIME, and I do use it all the time.  
                First of all, 
                in your case, use file_get_contents() rather than fopen and fread and such.  I use fopen() very rarely 
                verus "fgc". 
            </p>
            
            <p>kwas() does something like "or die()" but I like mine better for a number of reasons.  Your code snippet 
                just gave me an idea I should have had ages ago.  I need to test something....
            </p>
            
            <p>Ok, I just changed kwas() to return a truthy (yes, that's a technical word) value.  
                
            </p>
            
            <p>So now your code would look something like the following.  I'm also going to change your path.  The path issue
                might, in fact, be your problem.  Also, if you're not using variables or a newline or something that needs 
                to be substituted, use ' (single quotes) rather than " (double quotes). The __DIR__ is a more definitive way of saying 
                "this file's directory."  
                Simply using "." has issues that I have not entirely thought through.  I am not guaranteeing the following 
                will run.  I'm giving you the idea.  I'll never finish this if I test every snippet.
            </p>
            <pre>
$path = __DIR__ . '/last-updated.txt';
echo(kwas(file_get_contents($path), "reading $path failed or was 0 bytes"));
            </pre>
           
            <p>All this may still leave you with another set of problems, so more stuff:</p>
            
            <h6>CLI versus web</h6>
            
            <p>Part of the problem you're having is that you're just getting a 500 error with no details.  There are 
                several ways to deal with that.  
             </p>
             
             <p>PHP is run in CLI (command line) mode or various web modes.  Rather than figure out all the web modes, I have 
                 always found that logical "NOT cli" always means web mode.  I address this more specifically below.  
             </p>
             
             <p>I mentioned /etc/php/8.0/cli and /.../apache2  So that means that there is a different configuration for 
                 each, and thus different defaults.  There are several relatively subtle differences in running PHP each way.
                 In case it's not clear, cli mode means "$ php blah.php" and web mode means Apache or another web server is 
                 running the PHP.
                 
             </p>
            
           <p>Generally speaking, you can at least partially run your PHP web files from the command line.  In your 
               case, I think you'd see your bug from the command line.  Meaning "$ php index.php" or your equivalent.  It's a 
               recent practice of mine, so it's not burned into me,  but I'm starting to think you should go somewhat out of your 
               way to make sure your web PHP can run as seamlessly as possible as CLI (command line) for dev and debugging purposes.  That is, you may have to 
               fill in stuff that would otherwise be filled in from Apache.  Running in web mode is somewhat more painful for a number of reasons, so 
               you should leave yourself the CLI option.
           </p>
           
           <p>kwutils has iscli() to indicate CLI (command line) mode versus web mode.  It in turn it is using PHP_SAPI === 'cli' 
               where PHP_SAPI is a runtime superglobal variable provided by the PHP interpreter.  I mention this because in 
               order to make your code dual-use (cli and web), you'll sometimes need to use that.
           </p>
           
           <p>When you have the NetBeans PHP debugger working, you can see all the superglobals and their values.  
               
           </p>
           
           <h6>error.log and error display config</h6>
           
           <p>Did you look at /var/log/apache2/error.log  ?  That probably has the specific error.
               
           </p>
           
           <p>By default, web PHP turns off displaying errors because displaying errors (when there are errors) allows anyone on the web to get variable names and 
               such and thus make various injection attacks easier.  
           </p>
           
           <p>Your development machine is exposed to the web, and I'd imagine if you look at your access logs, you'll see that others have already found it.  
               You're running with a 32 bit (IPv4) address, and there are so relatively few of those that bots can find many of them easily enough.  (I would 
               not assume that 128 bit (IPv6) is better protection.  I'd imagine the hackers have already narrowed down what's in use.)
           </p>
           
           <p>I mention this because changing the error display even on your dev machine will be seen by the world, and your app will hopefully soon be used 
               in "the real world."  We should both give some thought to the implications, but I would err on the side of everyone seeing you err.  :)  As 
               you see various messages, we should both consider what anyone could get from that.  Otherwise put, this is a case of "security by obscurity" probably 
               not being particularly secure.  
           </p>
           
           <p>Besides, this is a small shop, not a bank or crypto exchange.  You can almost certainly use PayPal (or others) such that the user's data is not in your 
               system, or at least it's minimally in your system.  
               
           </p>
           
           <p>With all that said, to turn on errors, change this in /etc/php/8.0/apache2/php.ini:       </p>
           <pre>
; Kwynn
display_errors = On
           </pre>
           
           <p>Then restart Apache.  (The above is line 503 in my file.)
               
           </p>
           
            
        </section>
        
        <section id='misc_files_as_audio_2_2021_12_1'>
                   
            <h5>misc audio files as "music" - part 2</h5>
            
            <p>This is my 2nd entry and 3rd "h5" header for today.  This also gets off topic from web dev, but this is a continuing discussion with one of my 
                apprentices, so I'll leave it here.
            </p>
            
            <p>This is a followup to <a href='#2020-1120-arb-file-music'>non-audio files played as "music."</a>  First of all, the "stop" button works for me on 
                Firefox 95 Ubuntu desktop.  I haven't checked my web logs to see which user agent you're using.  If you come up with a fix, I will almost certainly post it 
                as long as it also works for me.  I am not going chasing that bug now.  You can add it to the endless list of stuff we might do much later.
             </p>
             
             <p>As for how it works...  Any audio recording encodes a series of volume levels; it's only a matter of how it's encoded.  A CD 
                 "is a two-channel [stereo] 16-bit ... encoding at a 44.1 kHz sampling rate per channel."  (1 / 44,100) === 0.000022676 or 22.676 &micro;s.  So, 
                 every ~22 microseconds the recording system records the volume of each microphone as a 16 bit number, so 65,536 possible volume levels.  
             </p>
             <p>The .WAV may be the original computer sound format.  A quick search shows that the original WAV format was the same bitrate as a CD and that
                 SatanSoft once again rears its head.  A WAV has a 44 byte header and then the rest of the file is audio encoded as above or else variants of 
                 the sample rate and volume bits.  For the "symphony," I used 8 kHz and whatever the default volume bits are.  
             </p>
             
             <p>The commands I used to create the WAV are just above the "play" button.  I took an Ubuntu install ISO file and treated its bits as sound.  
                 (The ffmpeg command added a WAV header.)
                 The result was interesting.  It has a beat and an odd sort of music.  There's no telling what other files would sound like.  I'd imagine 
                 people have played with that.
                 
             </p>
              
        </section>
        
        
        <section>
        <h5>Firefox caching</h5>
        
        <p>First of all, remember that you usually need to refresh a page before you see changes.  Firefox can be stubborn about that.  By default, 
            Firefox does a soft refresh.  Control - F5 should do a "hard" refresh, but even that doesn't always do the job.  The problem gets 
            worse with mobile browsers and external JavaScript and CSS.  Consider putting versions or unique timestamps in all the relevant files
            to see if the right page is shown.  Sometimes changing the query on the page helps refresh it, such as /?blah=1 /?blah=2 etc.  The query
            doesn't have to be meaningful or used, but the browser interprets that as a different page, so it may refresh the cache.
        </p>

        
        <p>When testing mobile, I have had to put JavaScript back into the HTML page as the easiest way to force a refresh of the JS.
            
        </p>
        
        <p>To check CSS, sometimes I change the color of a certain element just to check the version.  With JavaScript you can set a version 
            with document.getElementById('versionElementForFileXYZ_JS').innerHTML = '2021_1225_1846_25_EST'; 
            
        </p>

        
        <p>I have never taking the following to this extreme, but I suggest a technique below.  Rather than going to extremes, once you're aware of 
            the problem, you can usually eventually get everything to refresh.  Also, I'm sure I'm missing options.  I haven't gone looking all that 
            hard once I understood what the problem was.</p>
            
        <p>A perhaps too extreme measure would be combined server and client code that checks disk timestamps against what's rendered.  
            For CSS, the server code would create a CSS tag like ".cssV20211225_1843_22_EST" or both human readable and a UNIX Epoch timestamp.  
            Then the JavaScript would do a CSS selector query for the existence of that CSS tag.
        </p>
        </section>
        <section>
            <h5>W3 validator referer</h5>
            
            <p>Update: see my first January 13, 2022 entry.  The "referer" generally won't work anymore.</p>
            
            <p>Always point the validator check to https rather than http, such as 
                https://validator.w3.org/check?uri=https://blah.example.com/page1.html.  
                If you try to validate a secure page with an http link to W3, it won't 
                work because the browser will not send a referer from a secure page to a non-secure page.
                
            </p>
            
            <p>As to why "/check?uri=referer" works, I think I implicitly assumed for very long time that this was some sort of standard.  It's 
                much simpler, though.  It's specific to that particular W3 validator tool.  Whoever made that tool can write his "?" queries however 
                he wants.  It's written such that if you use the "referer" HTTP query argument, the code checks the HTTP request header 
                for the "Referer".  Look at your network traffic, and for a 
                .ico or .png or .js or whatnot, you'll see a "Request header" "Referer" field which is a link back to the HTML or PHP page that 
                called the .js file or whatnot.  The W3 code reads that referer and thus knows what page to 
                fetch.  (control-shift-I and then the "Network" tab shows you the network traffic AFTER you load that tab, so you will have to refresh.)
            </p>
            
            <p>I wouldn't call it an "API," either.  Again, it's much simpler than that.
                
            </p>
            
            <p>As for how I knew to link that way, I found <a href='https://dev.w3.org/validator/htdocs/docs/users.html'>the documentation</a>, 
                but I found it because I knew to look for it.  Off hand, I did not quickly see that linked from the validator itself.  Upon 
                thought, my best memory is that my webdev professor in 2005 showed us that technique.  He definitely pointed us to the validator.  
                
                
            </p>
            
            <p>As for reading request headers in PHP, one option is apache_request_headers().  I use this in my CMS 
                <a href='https://github.com/kwynncom/cms/blob/ae1da0f3ab68ca03e66f55047a28ec85e1d78fbe/ETagDM.php'>ETag and modified time 
                test</a>, function exit304IfTS() at the bottom.  I think I only implement one of the two so far.  It's on my agenda to implement 
                the other.
            </p>
                       
            

            
        </section>
        
    </section>
    
    
    <section>
        <h4>December 24 - 2 entries (so far)</h4>
        <section>
        <h5>16:38 EST entry</h5>
        <p>This continues a discussion with one of my apprentices, so I may switch from "he" to "you" again.</p>

        <p>Today's edition begins with a question about a template and pulling from a database versus hard-coding the menu (see yesterday's entry below).  He was 
            concerned about loading delays.  
            You'd have to be the average Indian so-called developer to delay loading that much, or a white American who doesn't understand databases worth a darn 
            and uses loops instead of SQL joins.  I once had a manager try to tell me that the queries were "very complicated" and thus they took several seconds.  
            The queries were trivial, and the code should have run literally several hundred times faster.
        </p>

        <p>The point being that loading delay in the context you mean has not been a problem on any hardware in the last 10 - 15 years.  

        </p>
        
        <p>You bring up a more interesting point, though.  There is always a tradeoff between making data entry easy versus the entry code making the 
            overall system much harder.  Otherwise put, how much trouble do you want to go to at various stages of the project to make it easy for the pizza shop 
            folk to make changes?  Given my philosophy of "make something work now versus frittering on perfection forever," I would not worry yet about 
            letting them make changes.  At the start, you're presumably going to be on hand pretty much every day.  Get the system making money, then decide 
            when it's worth making the tradeoff to let them take some of the workload.  
        </p>
        
        <p>With that said, this brings up the question of validating prices on the server side.  Say you hard-code $5 as the price of an item.  The client 
            orders one of them, but the client is mischievous and lowers the price to $1.  You should always check such data on the server side.  So this 
            brings up the interesting question of how to encode the price such that it can both be rendered and checked easily.  Putting the price in various 
            data formats makes sense: a database, a CSV file, a JSON file, XML, raw text, etc.  Then you'd have to do a bit of processing to render it, but you'd 
            have the validation on hand.  
        </p>
        </section>
        <section>
        <h5>17:42 entry</h5>
        <p>You mentioned a data object, or a DAO: data access object. This brings up a big question that has many possible good answers: how do you go about getting 
            from the database to the HTML?  I have gone back and forth between two methods.  I give examples of both further below, once I explain them.
        </p>
        
        <p>I'm about to explain my interpretation or variant of the <a href='https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller'>MVC pattern or 
                framework</a>--model view controller.  The model is the database 
            code that works with the data model.  You might call this the far back end (server-side).  The controller is in the middle and interacts between the other 
            two.  The controller might be on the back end or front end (browser client).
            The view is the code that creates the human readable format including the HTML. The view may be 
            created either on the front end or the back end to a degree, but the end result is part of the definition of the front end because it's the front 
            side that the users sees.
            
        </p>
            
        <p>A DAO whose only job is to interact between 
            the database and the rest of the code is a good idea in some situations.  Less strict but sometimes more practical is code that accesses the 
            db and does the first round of transformations towards HTML. 
        </p>
        <p>Once again, you may want to make something work first, however you can.  
             Even 2 - 3 years ago (18 months ago?), I might make a big mess in terms of the code logic, but the end result worked.
            Then I started cleaning the code, sometimes.  Now I am actually starting to code with my variations on MVC.  You can see the step by step 
            progress in git commits.
        </p>
        
        <p>I've gone back and forth between two variants of MVC.  My jury is still out, but the technique I am starting to favor 
            goes something like this...  Write 2 - 4 layers of PHP code.  One or two layers fetch from the database.  The second back-end layer 
            may process the data closer towards the end product. Then you may have a layer that makes the data completely human readable, such as turning float 
            5.0 to string "$5.00"  This layer may also 
            do the loop that creates an HTML string of table data.  The final PHP layer can be echo statements embedded in HTML that write the final product.  
            
        </p>
        
        <p>Let's take my <a href='https://github.com/kwynncom/web-server-access-log-analysis/tree/4bc97de89ff0243aebad6e0235005e3aacd0d9eb/agents_sa'>very recent 
                user agent code</a>.  "p10.php" is the innermost layer.  Often I actually use the term "dao."  In this case I didn't, but p10 is serving as the 
                DAO and it's doing the loops that lay out the data in an array that is close to the HTML table format.  "p10.php" is the model.  "out.php" is the 
                inner view--the part of the view closer to the back-end model.  It changes integer 25000 to string "25,000" and has the loop that creates most of 
                the HTML.  Then the template.php has "echo()" functions to write the strings.         </p>
           
           <p>The other technique is to create JSON at the PHP side and then let client-side JavaScript process the JSON.  I did it that way in 
               a <a href='https://github.com/kwynncom/web-server-access-log-analysis/tree/30d9be12414223f03dcc130c6f2b8daf29a551fe/agent_sa'>previous user agent 
                   version</a>.                </p>
              
              <p>I think the more recent way is better, but I'll know more when I get back to my long-term paid project.  I'm going to have to make that decision 
                  soon.            </p>
        </section>
        
        <section>
            <h5>17:56</h5>
            
            <p>Regarding an internal "style" tag or external CSS:  I totally rewrote my <a href='/'>home page</a> yesterday and posted it an hour or two ago.  
               I was running all over the place adding "class" attributes.  I find it easier to have the class attribute and the relevant styling in the same page
               rather than switching back and forth.  This may depend on how big the file is, though.  For a big file, going up and down is harder.  
               As I said yesterday, one answer might make more sense during dev and another once you're done dev'ing. 
               I'm not making an argument against your point.  I'm just explaining my reasoning.  
             </p>
             
             <p>Regarding big files, here is a thought. When you create a php file, it *IS* an HTML file until the &lt;?php tag, like my "template.php" I mention above.  
                 One result of this is that you can use require_once() to add HTML fragments.  So, with a large file, you can have a central PHP file that calls subfiles
                 to put them together.
             </p>
        </section>
        
    </section>
    
    <section>
    <h4>December 23</h4>
    
    <p>This is in response to an apprentice's question.  He is continuing his own version of the <a href='https://github.com/kwynncom/pizza'>pizza shop 
            online ordering</a>.</p>
            
     <p>The following may or may not be off topic.  Perhaps it's past time to say that, as far as I know, he has a pizza shop in mind that simply sells 
         pizzas and is not owned by the man who is mysteriously the 49th most powerful man in Washington for owning a pizza shop.  (In all these years, 
         I'd never actually seen the text, but there he still is, 9 years later: 
         <a href='https://www.gq.com/gallery/50-most-powerful-people-in-washington-dc'>#49 James Alefantis</a>.)  You'll note that I put $5 or $10 
         on my version, not $15,000 because I'm selling something other than pizza.  
    </p>
    
    <p>In any event, I will try to keep my technical hat on.  In his version several hours ago, he had "pizza.php" and "salad.php" and such, activated 
        by clicking each category of the menu on the left side.  His asked my thoughts on this.
    </p>
    
    <p>I'll switch to "you" rather than he.  I have to start with my pet peeve.  You didn't close a div, so I'm sure your page is HTML5 invalid.  Firefox 
        "view source" shows the close body tag as red; that's why I noticed.  (I may have noticed by eye soon after.)
        
    </p>
    
    <p>I have to appreciate your use of ":hover" and "active" (Why is it :hover and .active?  That doesn't seem right, but it seems to work.)  Remember 
        that I try to avoid "pretty" web sites, so I'm only partially aware of such things.  I'm glad you reminded me because it's a useful cue to the 
        user.  I probably use JavaScript in situations where CSS does the job more naturally.
    </p>
    
    <p>You might consider pulling your styling into the one HTML page during parts of development.  There are arguments either way.  I find it useful to 
        have everything right there.  As you head towards going live, it probably makes sense to have an external style sheet, but I still argue with 
        myself about that.  I'm not sure there is one right answer, either.  You can cut and paste your CSS between the two such that the blank external 
        CSS is always there ready to go.  There is no reason to remove the "link" tag or delete the external stylesheet, unless you firmly decide to stay 
        within the HTML.  And when the previous version is in git, you don't even have to be firm.  :)
    </p>
    
    <p>Now to the original question: about using separate PHP files in that manner.  First of all, when you're doing one of your first web apps, 
        whatever works or even heads in the direction of working is progress.  With that said, there is no need to reload the page with full-page HTTP 
        calls in your case.  Once you have basics of the page, clicking on a menu category should call AJAX JavaScript and only refresh the center of the 
        screen.  The AJAX makes the call to PHP.  
        
    </p>
    
    <p>With *THAT* said, then you get into the question of "single page" PHP.  As much as I despise WordPress and Drupal, their notion of single page 
        probably has some merit, although I think they take it too far, and their version gets too complex.  Single page means that there is a web server 
        (Apache) rewrite in .htaccess that routes all requests through index.php.  The index then routes the requests as needed.  
     </p>
     
     <p>Then again, the single page thing may be too much for now.  I still have not used it when I'm writing from scratch, but I'm considering it.  I 
         may have an update on this in 2 - 3 weeks as I make this decision in a "real world," paid project.  (It's not a new project.)
     </p>
     
    </section> <!-- 12/23 -->
     
     <section>
     <h4>entry history</h4>
     
     <p>I expect I'l be revising this for a while, so it needs a history.</p>
     
     <ol reversed='reversed'>
         <li>nevermind.  I hope I labelled the entries well enough</li>
         <li>2021/12/24 17:56 EST - 3nd new entry, same</li>
         <li>2021/12/24 17:42 EST - 2nd new entry, labeled with timestamp</li>
         <li>2021/12/24 16:38 EST - new entry, labeled as "16:38"</li>
         <li>2021/12/24 15:53 EST - fixed Alefantis link</li>
         <li>2021/12/23 17:51 EST - prepping for first post</li>
     </ol>
     </section>
    



<section id='VOIP3-compilation-2-2021-0828'>
	<h3>2021, August 28 - Asterisk compilation revisited</h3>
	
	<p>This is a follow-up to <a href='#VOIP1-2-entry-2021-0822'>previous entries</a>.</p>
	
	<p>I have limited download bandwidth at the moment (long story), and I still haven't perfected VMs and / or Docker and such locally, so in order to get a 
		clean installation and compilation slate, I'll rent an AWS "on demand" instance.  Hopefully it will cost me 10 - 20 cents.  I want an x86_64 processor 
		so that it's closer to my own machine. I might as well get a local-to-my-instance SSD / NVME (as opposed to an EBS / network drive) for speed, and I 
		should use 
		"<a href='https://aws.amazon.com/ec2/instance-types/'>compute optimized</a>" because I will peg the CPU for a short while.  So my cheapest option seems to be 
		a c5ad.large, <a href='https://aws.amazon.com/ec2/pricing/on-demand/'>currently at $0.086 / hour in northern Virginia (us-east-1)</a>.
	</p>
	
	<p>Instance details: Ubuntu 20.04 (probably will remain the same until 22.04), x86 (just to make it closer to my local machine - "x86" is implied x86_64).  
		Type c5ad.large.  I would give it 12 GB storage for the EBS / root drive rather than the default 8.  8 GB may be too little.  Assuming you have a 
		VPC (VPN) and ssh keys set up, that's all you need.
	</p>

	<p>Today's greatly <a href='https://kwynn.com/t/21/07/asterisk/asterisk_build_improved_2021_0828.txt'>improved compilation commands</a>.  Notes on this below.</p>
	
	
	<p>For current versions, one of the <a href='https://wiki.asterisk.org/wiki/pages/viewpage.action?pageId=4817506'>first steps</a> calls for downloading 
		"asterisk-xx-current," so be sure to check the relevant <a href='https://downloads.asterisk.org/pub/telephony/asterisk/'>Asterisk download directory</a> 
		for higher versions.  Note that the versions are not in any useful order, so you'll have to look carefully and / or search.  The documentation still 
		references version 14.x.y.  I compiled version 18.
	</p>
	
	<p>When everything is compiled / you're done, the directories use exactly 1 GB (call it 1.1 GB to be safe), but that may grow with future versions.</p>
	
	<p>When running the step "sudo ./install_prereq install" note that the US telephone country code is 1     </p>
	
	<p>Note that downloading dahdi and dahdi-tools from Asterisk, as shown in their directions, will not work in recent Linux kernels (5.11 or earlier) 
		because the Asterisk versions are behind.  My instructions have you compile the source.</p>
	
	<p>The compilation of dahdi, dahdi-tools, and libpri are quick.  Asterisk itself almost exactly 5 minutes.  From reboot, elapsed time for this day's attempt #1 
		was 38 minutes; second attempt was about 23 minutes.  I forgot to check the final one.  I believe I posted attempt #4 above.
		
	</p>

			
	<p>My <a href='https://kwynn.com/t/21/07/asterisk/asterisk_build.txt'>previous attempt at compilation instructions</a> (days ago), just for the record.
		
	</p>
	
</section> 

<section>
	<h3>2021, August 22 - 25 - <a href='https://cardano.org/'>Cardano</a> / Ada cryptocurrency</h3>
	
	<p>As of several days ago, I have a Cardano 
		"<a href='https://docs.cardano.org/getting-started/operating-a-stake-pool/about-stake-pools'>stake pool</a>" running.  It is public, 
		but, for a number of reasons, I'm not going to advertise it, yet.
	</p>
	
	<p>These are notes on setting up a stake pool.  In short, a stake pool is the rough equivalent of a Bitcoin mining 
		node.  Bitcoin is "proof of work" (mining); Ada is "proof of stake" (user investing).  Bitcoin uses an absurd amount of energy to "mine."  
		Ada's trust is established by the community investing in stake pools.  That's the very brief sketch.  
	</p>
	
	<p>The <a href='https://docs.cardano.org/getting-started/operating-a-stake-pool/creating-a-stake-pool'>official instructions</a> are fairly 
		good, but, as is almost always the case, they leave a few things out, some things are clear as mud, they 
		make assumptions, etc.  These are my annotations.
	</p>
	
	<!-- **** LEDGER RAM ***** -->
	<section>
	<h5>hardware requirements</h5>
	
	<p>Because the instructions start with hardware requirements, I will, too.  I seem to be doing fine with 4 GB of RAM, HOWEVER... I have a big, 
		fat qualifier to that further below.  I am running two AWS EC2 "c5ad.large" type instances--one for the relay node, and one for the block 
		producer.    For "on demand" / non-reserved, $0.086 / hour 
		X 24 hours X 30.5 days (average month) X 2 instances (block producer and relay) = $126 per month just for the CPU.  Storage fees are more; that will take a while to nail down precisely;
		roughly, I'd say that's another $25 / month.  Note that reserving an instance--paying some in advance--cuts CPU prices in half.  See "reserved instances."
	</p>
	
	<p>I'll express drive space in two parts.  The EBS Linux root ( / ) is only using 2.4 GB with an Ubuntu Linux 20.04 image; the chain database is 
		NOT on root, though (see below). If you decide to save / log the output of the node, note that the block producer has produced 118 MB of output in 
		about 3.7 days; 242 MB in about 7 days.  	I assume the relay node is much less; I'll try to check later.  The block producer outputs every second because it's checking 
		to see if it's the slot leader.  The "slot leader" is the rough equivalent of winning the Bitcoin mining lottery and 
		producing a block on the blockchain.
	</p>
	
	<p>As for the chain database, it is currently 13 GB.  Based on everything I've seen, the rate of increase of the database is likely to grow 
		for weeks or months.  
		</p>

	<p>After that 3.7 days, I have only been charged 9 cents for 1 GB of output to "the internet" outside of AWS.  However, billing is several 
		hours behind.  (11 cents in 7 days)
		</p>
			
		<p>As for their assertion "that processor speed is not a significant factor for running a stake pool...." That appears to be true for the 
			most part, but there are some exceptions, just below.
			</p>
			
			<h6>exceptions to hardware reqs</h6>
			
			<p>Processing the ledger ($ cardano-cli query ledger-state --mainnet > /tmp/ledger.json ) used 4CPUs (cores), took 10GB of RAM, and 
				ran for about 5 minutes.  The ledger was 3.8 GB several days ago.  It compressed to 0.5 GB.  Don't try running this on a stake pool 
				node / instance unless you're sure it can handle it, and it's just not worth risking unless it can <b>really</b> handle it.
				
			</p>
			
			<p>I ran the ledger on an AWS EC2 c5ad.2xlarge instance.  I ran it for 0.8 hours X $0.344 / hour = $0.28.  That's how long it took me to copy the chain / database 
				from EBS to the local nvme (ssd), load up the Cardano binaries and basic config, sync the database between the saved chain and the current change, run the ledger, compress, 
				and download the ledger.
				
			</p>
			
			<p>Similarly, I would be careful running any queries on a live stake pool.  I have reason to believe that even short queries like 
				utxo will slow the system down enough that it may miss its slot.  In other words, a stake pool node show do nothing but route and 
				process blocks.  It should only be running the node; not foreground ad hoc commands.
				
			</p>
			
	</section> <!-- hardware -->
		<p>The instructions try to push you to compiling or Docker, but the binaries available for x86_64 Linux work just fine.  The binaries are 
			linked from 
			the <a href='https://github.com/input-output-hk/cardano-node'>cardano-node GitHub</a> or 
			the "<a href='https://hydra.iohk.io/job/Cardano/cardano-node/cardano-node-linux/latest-finished'>latest finished</a>" link.  I am using v1.28.0.
			</p>
	
			<p>You'll want to put the Cardano binaries path in your Linux PATH environment variable.  While you're at it, you should decide where you're going to put the Caradao socket.  
				It can be anywhere that your standard user has access to create a file.  
				Cardano runs as the standard user, not a sudoer or root.  I won't admit where I put mine because I'm not sure it's a good idea, but I call it, abstractly, 
				/blah/cardanosock which assumes the standard user has rwx access to /blah .</p>
			
			<p>Subsituting for your own binary path and socket, add these lines to ~/.bashrc :</p>
			
			<pre>
				export PATH="/opt/cardano:$PATH" 
				export CARDANO_NODE_SOCKET_PATH=/blah/cardanosock
			</pre>

			<p>
				Then don't forget to $ source ~/.bashrc    for every open shell.  The contents of .bashrc don't load until a new shell is open or you "source"
			</p>
					
			<p>I had never installed or used Docker before.  On one hand, I got it all running very quickly, but I haven't learned to deal with Cardano's Docker image limitations 
				yet. It was 40 MB when running, as I remember, which is impressive, but that leaves out too many commands.  I may start with an Ubuntu docker image and try to 
				build my own Cardano Docker image at some point.  Beyond a quick test, I have not used Docker.
				
			</p>
			
			<p>On the <a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/getConfigFiles_AND_Connect.md'>config file step</a>, I would 
				add that you need to use the same command, for both test and main, to get testnet-alonzo-genesis.json or mainnet-alonzo-genesis.json .  Use the same wget command 
				except substitute the appropriate alonzo file.
			</p>

			
			<p>Wherever you see --mainnet , you subtitute "--testnet-magic 1097911063" (without quotes) for the current testnet.  The 
				<a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/keys_and_addresses.md'>addresses step</a> shows you how to create a test 
				address such as addr_test1xyzabc123....  In the testnet, you get test Ada (tAda) to 
				play with from the <a href='https://testnets.cardano.org/en/testnets/cardano/tools/faucet/'>faucet</a>.  Enter an address such as the above.  
			</p>
			
			<p>Note that you won't see your funds in 
				<a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/simple_transaction.md'>utxo</a>
				until your node catches up with the chain.  I don't remember how long that took in test: somewhere between 1 - 5 hours.  The config file page 
				above shows you how to query your tip. Note that a slot is created every 1 second, so you are comparing your progress against 
				historical slots.  You can see where the test and main chains are at the <a href='https://explorer.cardano-testnet.iohkdev.io/'>test Explorer</a> and 
				<a href='https://explorer.cardano.org/en'>mainnet Explorer</a>.  An epoch is 5 days, although I don't know if that ever changed.  We are currently in the "Mary" era; 
				I am still not sure if that's the same as the "Shelley" era.  
			</p>
			
			<p>For reference on the slot currents times, from which you can calculate the origin:</p>
			
			
			<table>
				<tr><th></th><th>slot (elapsed seconds)</th><th>as of</th></tr>
				<tr><td>mainnet</td><td>38382516</td><td>2021/08/26 03:33:27 UTC</td></tr>
				<tr><td>testnet</td><td>35579709</td><td>2021/08/26 03:35:25 UTC</td></tr>
			</table>
			
			<p>On a similar point, if you are still syncing, when calculating your 
				<a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/simple_transaction.md'>"--invalid-hereafter"</a> 
				make sure to calculate against the live chain, not your tip.  Otherwise, your transaction will be immediately invalid (or will have been invalid a year ago).
				
			</p>
			
			<p>The mainnet takes something like 27 - 35 hours to sync.  Given that the chain is a linear chain, only 1 CPU / core can be used.  Note that the density of data 
				goes way up in the last several months, so you'll plow through historical seconds / slots, and then it takes much longer to process the last few months.  
							
			</p>
			
			<p>I never got the mainnet loaded on my own computer.  For one, the fan ran like I've never, ever heard it before.  One day I will likely sync my computer by 
				downloading the chain (see more below).  
			</p>
			
			<p>Regarding utxo and transactions, it wasn't until one of the final steps that I was confronted with a situation where the payment of the 500 Ada stake pool deposit 
				had come in 4 transactions, which is 4 utxos.  I had to use 3 utxos to get enough Ada.  Below I am shortening and making up utxo addresses / ids: </p>
			<pre>
cardano-cli transaction build-raw \
--tx-in abcde#0 \
--tx-in abcdf#0 \
--tx-in abcdg#0 \
--tx-out $(cat payment.addr)+0 \
--invalid-hereafter 0 \
--fee 0 \
--out-file tx.draft \
--certificate-file pool-registration.cert \
--certificate-file delegation.cert
			</pre>
				
			<p>That command comes from the <a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/register_stakepool.md'>stake pool 
				registration page</a>.
			</p>
			
			<p>Also when building transactions, keep track of the tx.raw and tx.draft.  The draft command and raw command are similar, so it's easy to get that confused.  Look at the 
				timestamp and file order of the tx.raw and tx.draft to help keep track.  If you mess this up, you'll get a "ValueNotConservedUTxO" error, mixed in with a bunch of other 
				gibberish (partial gibberish even to me!).
				
			</p>
			
			<p>Once you submit a transaction successfully, it will show up in the Explorer (see above) within seconds, perhaps 20 seconds at most.  Deposits show up in the Explorer 
				as deposits.
				
			</p>
			
			<p>Regarding topology:</p>
			
			<pre>
block producer (I changed the exact address, but it is a 10.0.x.y, which is the relay's address on the same VPC):

$ more kwynn-block-producer-topology-2021-08-1.json
{
  "Producers": [
    {
      "addr": "10.0.157.52",
      "port": 3001,
      "valency": 1
    }
  ]
}
			</pre>
			
			<p>Assuming the block producer is running on port 3001, the block producer firewall only needs to admit 10.0.157.52/32 for TCP</p>
			
			<p>relay:</p>
			
			<pre>
$ more kwynn-topology-relay-2021-08-1.json
{
  "Producers": [
    {
      "addr": "relays-new.cardano-mainnet.iohk.io",
      "port": 3001,
      "valency": 2
    },
    {
      "addr": "10.0.157.53",
      "port": 3001,
      "valency": 1
    }
  ]
}
			</pre>
			
			<p>The relay needs to admit "the world" on TCP 3001 (or whatever port it's on) because it's receiving from the world.
				
			</p>
			
			<section>
				<h5>final stake pool steps / public pools</h5>
				
				<p>Using <a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/register_stakepool.md'>Github for storing metadata</a> is a good idea.  
					Note that the <a href='https://git.io/'>git.io</a> URL shortcut will work for anything in GitHub, including repository files or specific repository versions.  That is, 
					you don't have to use a Gist.  I am using a standard repo file and / or a specific version; I don't remember what I settled on.  The metadata hash is public, so 
					I saved it in the repo. </p>
				
				<p>(My site is getting queried 30 times a day for testnet; I really need to de-register that thing one day, and return the utxo to the faucet.)</p>
				
				<p>You have to pledge something in the "cardano-cli stake-pool registration-certificate" command, but it seems that it doesn't matter what you pledge.  I would assume that the 
					amount has to be in payment.addr, though.  The pool cost must be at least the minimum cost as defined in protocol.json in "minPoolCost".  pool-margin can be 0 but must be
					set.  You do not need a "single-host-pool-relay" if you're not using one; an IP address does fine.
				</p>
				
				<p>As far as I understand, you do not need a metadata-url or metadata-hash, but that's what defines a public pool.  See below.								</p>
				
				<h5>public pools specifically</h5>
				
				<p>This <a href='https://docs.cardano.org/getting-started/operating-a-stake-pool/public-stake-pools'>Cardano Docs page appears to define what a public pool</a> is, but 
					so far I can't get my client's ticker to list on <a href='https://adatools.io/'>AdaTools</a>.  I can get it to list on AdaTools and <a href='https://pool.vet/'>Pool.vet</a> 
					by pool id:
					</p>
					
					<p>What I think of as the <a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/register_stakepool.md'>final stake pool registration page</a> 
						has this command: 				</p>
					<code>cardano-cli stake-pool id --cold-verification-key-file cold.vkey --output-format "hex"</code>
					
					<p>That pool ID is public--it's in the public ledger.  It begins with "pool".  I'll use other pools as examples, but both show by poolID: 
						<a href='https://adatools.io/pools/pool1g79uyzvt9mm3z7jdcxnp36n4egm4z6l8c6n9l2mk8ae2yf5zman'>AdaTools by pool ID</a> and 
						<a href='https://pool.vet/#pool1g79uyzvt9mm3z7jdcxnp36n4egm4z6l8c6n9l2mk8ae2yf5zman'>Pool.vet by pool id</a>.
					</p>
					
					<p><a href='https://pool.vet/#ABC'>Pool.vet by ticker</a> works for my client, but AdaTools does not find it in <a href='https://adatools.io/pools'>its search</a>.
						
					</p>
					
					<p>More importantly, he can't find or pledge to his pool in his Cardano Daedalus wallet.  Otherwise put, I seem to be having problems declaring his pool "public," even 
						though pool.vet shows that the metadata hashes match.  My only theory at this moment is that I created the pool during epoch 285; epoch 286 is now, and I set it 
						to retire at the end of 286.  It's possible that the wallet won't show a pool set to retire in a few days.  I thought I had 
						properly <a href='https://github.com/input-output-hk/cardano-node/blob/master/doc/stake-pool-operations/retire_stakepool.md'>un-retired the pool</a>, but 
						results are uncertain after several hours.  So far I haven't processed the ledger again to see if the retirement is cancelled.  
						
					</p>
				
				
			</section>
			
			
			<h5>entry history</h5>
			
			<p>I wrote much of this on August 22, 2021.
				
			</p>
		
		
			<section>
				<!-- CARDANO TO DO ********************* -->
				
			<h5>stuff to update (note to self)</h5>
			
			<ul>
			<li>Billing updates, days and weeks later.</li>
			<li>Relay log size increase versus block producer</li>
			<li>How sensitive is a node to queries such as utxo?</li>
			<li>Calculate / script / track main and test slot origin time</li>
			</ul>
			</section>
</section>


<section id='VOIP1-2-entry-2021-0822'>
	
	<!-- ********** VOIP ************* -->
	
	<h3>2 VOIP / SIP / Asterisk / voicemail entries:</h3>
	
	<section>
		<h3 id='eh3-2021-08-13-voicemail'>2021, August 22 - VOIP / SIP / Asterisk - voicemail working</h3>
		
		<p>Per my <a href='#eh3-2021-07-26-voip-sip'>previous entry (7/26)</a>, I got voicemail working on July 31.  It's taken me a while
			to write it up in part because I started another project that I hope to write up soon.
						
		</p>
		
		<p>I wound up changing my Asterisk system to UDP, so if you're following along at home, be sure to set Amazon Chime's console to UDP.  
			For the moment that's step 16 in the previous entry.
		</p>
			
		<p>The outgoing voicemail message is limited to a subset of audio formats and "settings."  I used an 8kHz, 32 bit sample, mono file.
			I'm almost certain one can use a higher sampling rate, but it will do for now.  The Linux / Nautilus metadata says a 128 kbps 
			bitrate for that file.  I assume the math works out.  I leave that as an exercise to the reader.  My file is kwprompt3.wav placed 
			in /var/lib/asterisk/sounds/en   .  You'll see the kwprompt3 without the wav necessary in  
			<a href='https://kwynn.com/t/21/07/asterisk/asterisk_conf_voicemail.txt'>extensions.conf</a>.
		</p>
							
		<p>The big problem I had getting voicemail working was that everything would work fine, and then Asterisk would hang up after 30 seconds.
			That's particularly funny because my potential client is seeking developers because none of the VOIP / voicemail providers allow 
			a voicemail over 10 minutes.  My client potentially needs several hours, or perhaps somewhat beyond that.  Effectively, he needs 
			unlimited voicemail.
		</p>
		
		<p>The two keys that led me to a solution were setting 
			<a href='https://kwynn.com/t/21/07/asterisk/asterisk_conf_voicemail.txt'>logger.conf</a> to give me very verbose outputs--the 
			(7) indicates 7x verbosity.  I've seen examples give 5x, so I don't know if 7x gives any more, but it works.  The other key was 
			to set "debug=yes" in pjsip.conf, shown in the same file above.
			</p>
			
		<p>When I called the voicemail phone number and looked at /var/log/asterisk/full, I would see the SIP INVITE transmitted over and over.
			I don't remember which way the INVITE goes; the packets are sometimes hard to interpret.  In each INVITE, I would see 2 lines that 
			began with "Via: SIP/2.0/TCP" and "Via: SIP/2.0/UDP"  The lines were next to each other.  The TCP line was to an external IP address; 
			the UDP line was to an internal IP address (10.0.x.y). The Amazon Chime system that was routing the call to me is definitely external 
			to my AWS VPC / VPN, so this was a big hint: the INVITE exchange was not being completed because the packet wasn't going from my system 
			to the external internet.  After 30 seconds, Asterisk would issue a SIP BYE command and hang up.
		</p>

			<p>It took me several hours to stumble across the solution: at least one of the entries "external_media_address" and 
				"external_signaling_address" in pjsip.conf (see previous conf links).  I set them to the external IP address (Elastic IP) 
				of my Asterisk instance / virtual machine.  Then it worked!
			</p>
			
			<p>Given my setup, the voicemails are stored in /var/spool/asterisk/voicemail/vm-try1/1/INBOX  .  The same voicemail is stored in 
				3 formats.  I assume that is the line in voicemail.conf "format = wav49|gsm|wav"  That's a 1990s era raw wav format, a modern, 
				compressed WAV format (wav49, apparently), and a gsm format. The WAV and GSM are of a similar size.  Given the purpose of this 
				project, keeping the raw wav format is probably worthwhile.  Off hand, I hear very little difference, but I have not tested that 
				hard and with very many voices / conditions.
			</p>
			
			<p>So far my potential client left a 42 minute voice message which, as best I can tell, worked fine.  (I have not exhaustively 
				tested it, but that's another story.)
 		</p>
	</section>

	<section id='eh3-2021-07-26-voip-sip'>
	<h3>2021, July 26 - VOIP / SIP (last revised roughly 9:30pm my time)</h3>
	
	<p>The result of the following is that I reserved a phone number and dialed it and got literally "hello world" from my Asterisk server.  
				
	</p>
	
	<p>A few days later I had voicemail working.  Voicemail is in my <a href='#eh3-2021-08-13-voicemail'>August 13 entry</a>.</p>
	
	<section>
	<h4>Asterisk</h4>
	<p>I answered an ad about VOIP.  The key of the project was that the client needs to be able to leave more-or-less arbitrarily long 
		voice messages.  I haven't gotten to the point of just how long, but definitely well over 10 minutes.  I would guess that an hour is 
		needed.  The problem they had is that they talked to 15 VOIP providers and noone went over 10 minutes.
		</p>
		<p>I had a brush with a VOIP project in early 2016, and I've always wondered "What if?"  I played some with the 
			<a href='https://www.asterisk.org/'>Asterisk</a> software but 
		couldn't make much of it.  I compiled it and had it running in the barest sense, but didn't get it to do anything.  Asterisk is of 
		course free and open source.
		</p>
		<p>In part because I had unfinished business from 2016, I started experimenting.  Then I got obsessed and started chasing the rabbit.  
			After about 21 hours of work spread over a week or so, I have most of the critical elements I need in two "pieces"--part in the 
			cloud and part on my own server.  
		</p>
		
		<p><b>UPDATE</b>: I <a href='https://kwynn.com/t/21/07/asterisk/asterisk_build_improved_2021_0828.txt'>greatly improved</a> the following on August 28.  
			I eliminated all "tail chasing."  I also wrote up new notes in a <a href='VOIP3-compilation-2-2021-0828'>new blog entry</a>.
			
		</p>
		<p>Here is an attempt at an edited version of my 
			<a href='https://kwynn.com/t/21/07/asterisk/asterisk_build.txt'>Asterisk install command history</a>.  One important note is that 
			some of that was probably tail chasing versus:<br/>
			sudo ./install_prereq<br/>
			sudo ./install_prereq install<br/>
		</p>
		
		<p>Then I changed <a href='https://kwynn.com/t/21/07/asterisk/asterisk_conf.txt'>4 config files</a>.</p>
		
		<p>Probably more to come, but I have an apprentice live right now reading this.</p>
	</section>
	<section>
		<h4>AWS</h4>
		
		<p>In almost all cases, the AWS documentation is excellent.  In this case, I chased my tail around.  In the end, I got 
			somewhat lucky.  Of all the weird things, I have the darndest time finding the right AWS console.  The link is 
			for the <a href='https://console.chime.aws.amazon.com/home/'>AWS Chime</a> product including "voice connectors."  So 
			THERE is the console link.
			
		</p>
	</section>
		
	<p>I have the <a href='https://kwynn.com/t/21/07/asterisk/hello-world.gsm'>"hello world" voice</a> which will probably download and not 
		play.  Someday perhaps I'll make it play.  It's a lovely, sexy female voice--a brilliant choice on the part of the Asterisk folk.
		REVISION: I got some grief over "sexy."  Perhaps she's only sexy when you've spent 21 hours getting to that point.
	</p>
	
	<p>I just confirmed that the Chime console does not save in your "recently used" like everything else does.  So I'm glad I recorded the 
		link.  		
	</p>
	
	<p>At the Chime console, you'll need the 32 bit IP (IPv4) address of your VOIP server, or domain name.  With only a bit of trying and study, I 
		could not get 128 bit IP addresses (IPv6) to work--they were considered invalid. 	</p>
	
	<ol>
		<li>At the Chime console, go to "Phone number management," then "Orders," then "Provision phone numbers."</li>
		<li>Choose a "Voice Connector" phone number.  (I am using SIP, but don't chose that option.)</li>
		<li>Choose local or toll free, then pick a city, state, or area code. Pick a number or numbers and "provision."</li>
		<li>After "provision" / ordering, it may take roughly 10 seconds to show up in the "Inventory" tab.  You can use the table-specific 
		refresh icon to keep checking (no need to refresh the whole page)</li>
		<li>Go to "Voice connectors" and "Create a new voice connector"</li>
		<li>The name is arbitrary but I believe there are type-of-character restrictions</li>
		<li>You'll want the same AWS region as the VOIP / SIP server.</li>
		<li>I have not tried encryption yet, so I disable it.  (One step at a time.)</li>
		<li>"Create"</li>
		<li>click on the newly created connector</li>
		<li>Go to the "origination" tab</li>
		<li>Set the "Origination status" to Enabled</li>
		<li>Click a "New" "Inbound route"</li>
		<li>Enter the IP address or domain of the Asterisk "Host"</li>
		<li>the port is 5060 by default</li>
		<li>protocol is whatever you set the VOIP server to.  I used TCP for a test only because it's more definitive to tell if it's listening</li>
		<li>set priority and weight to 1 for now.  It's irrelevant until you have multiple routes.</li>
		<li>Add</li>
		<li>Save (This addition step trips me up.)</li>
		<li>Go to the "phone numbers" tab and "assign from invenstory."  Select your phone number and "assign..."</li>
		<li>Set /etc/asterisk/extensions.conf to the phone number you reserved (see my conf examples above)</li>
		<li>Restart Asterisk if you changed the number.  There is a way to do it without restart.</li>
		<li>make sure Asterisk is running - I find it best to turn it off at the systemctl level and simply run "sudo asterisk -cvvvvvvv"  Leave
		the Asterisk prompt sitting open so you can see what happens</li>
		<li>open up port 5060 at the AWS "security group" level for that instance</li>
		<li>Dial the number and listen to "Hello world!"</li>
	</ol>
	
</section>

</section>

<section>
	<h3>2021, July 8 - zombie killing</h3>
	
	<p>I can now add zombie killing to my resume.  I logged into this website roughly 30 minutes ago and was greeted with the 
		"motd / message of the day" message that there were 75 zombie processes.  I barely knew what a zombie is.  
		</p>
		<p>First I had to find out how to ID a zombie.  The answer is  ps -elf | grep Z   &nbsp;&nbsp; My new 
			"<a href='https://github.com/kwynncom/simple-time-server'>simptime</a>" / simple time server 
		was causing the problem.  
		<p>
		It didn't take long to more or less figure out what a zombie is, but it took just slightly longer to find what to do about it.  
		When a process forks, the parent is supposed to be fully attentive waiting to receive the exit / return value of the child, or it 
		is supposed to make itself available (signal handler) to receive the value.  
		If the parent is sleeping or waiting for something else, the parent never reads the return, and the child's entry stays in the 
		process table.  The child is dead and not using any other resources, but one potential problem is that the process table fills up.  
		Another problem is that the ps command (depending on switches) shows a bunch of "defunct" entries.  (Similarly, there may be 
		more entires in /proc/).  
	</p>
	
	<p>A <a href='https://www.geeksforgeeks.org/zombie-processes-prevention/'>Geeks for Geeks zombie article</a> explained how to stop 
		the zombies; I chose the SIG_IGN option which tells the OS that the parent doesn't care what the exit value is, so the child's 
		process entry is removed.  I don't care because, for one, I have other ways of testing whether the system is working.  For another, 
		the parent can't "wait()" in my case because its job is to immediately start listening for more connections.  Another option is a 
		signal handler, but there is almost no benefit to the parent knowing the value in my case.  Again, I have other ways of testing 
		whether everything is working.
	</p>
		
</section>

<section>
	<h3>2021, July 5 - yet another round with a blasted CMS</h3>

	<p>I have encoded below my software dev rule #4 about being careful of CMSs.  I got burned again last night--Happy July 4 to me!  I am building an Ubuntu 21.04 environment from scratch as opposed to upgrading.  There are several reasons, but I suppose that is another story.  Anyhow, I was trying to get Drupal 7 to run in the new environment.  Upon a login attempt, I kept getting a 403 error and "Access denied" and "You are not authorized to access this page" even though I was definitely using the right password.
	</p>
	
	<p>To back up, first I was getting "PHP Fatal error:  Uncaught Error: Undefined class constant 'MYSQL_ATTR_USE_BUFFERED_QUERY' in /.../includes/database/mysql/database.inc"  Thankfully I remembered that it's Drupal's crappy way of saying "Hey, you don't have php-mysql installed," so sudo apt install php-mysql  Note that you have to restart Apache, too.  
	</p>
	
	<p>Similarly, Drupal's crappy way of saying "Hey, you don't have Apache rewrite installed" was a much more tangled path.  I foolishly went digging in the code with the NetBeans debugger.  
	This is a case of "When you're not in the relevant parts of Africa, and you see hoof prints, think horses, not zebras."  I assumed a problem with Drupal rather than the obvious notion that 
	something wasn't set up right.  
	</p>
	
	<p>I eventually got to code that made it clear that the login was not being processed at all.  By looking at the conditions, I eventually realized that Drupal wasn't receiving the login or password.  Then I realized that none of $_REQUEST, $_POST, or $_GET were showing the login and password. So I searched on that problem and quickly realized that it was a rewrite / redirect problem.
	<br />sudo a2enmod rewrite<br />
	sudo systemctl restart apache2<br />
	<br />
	Problem solved!  I won't admit after how long.
	</p>
	
	<p>I was inspired to <a href='https://github.com/kwynncom/code-fragments/tree/3027cdc9688da4ebcb33298ec96cd9af58fbb71e/isrewrite'>write some code</a> for the "Never again!" category (a more legitimate use of the phrase than some, I might add).  
	
	</p>

</section>

<section>
	<h3>2021, March 4 - 5 - Robo3T copy</h3>
        
        <p>The <a href='https://robomongo.org/'>makers of Robo3T</a> have started asking for name and email when you download.  R3T is of course free 
            and open source (software - FOSS), as is almost everything I use.      I got the latest version 
            directly from them, but I thought I'd  provide it for others.  Providing it for others is part of the point of FOSS.  
            
        </p>
	
	<p><a href='https://kwynn.com/t/21/02/robo3t-1.4.3-linux-x86_64-48f7dfd.tar.gz'>Download - robo3t-1.4.3-linux-x86_64-48f7dfd.tar.gz</a></p>
        
        	<pre>
SHA256(robo3t-1.4.3-linux-x86_64-48f7dfd.tar.gz)= a47e2afceddbab8e59667facff5da249c77459b7e470b8cae0c05d5423172b4d
Robo 3T 1.4.3 - released approximately 2021/02/25	</pre>
        
        <p>I'm messing with this entry as of the 5th at 12:08am my time.  I first posted it several minutes ago.</p>
</section>

<section>

<h3>2021, Jan 31 - yet more on time measurement and sync</h3>

<p>I'll go back a year and try to explain the most recent manifestions of my time-measuring obsession.  I wasn't so much interested in keeping my computer's time 
super-accurate as I was interested in how to compare it with "official" time.  Otherwise put, how do I query a time server?  The usual way turned out to be somewhat difficult.  (It just 
occurred to me a year later that perhaps NTP servers don't check the incoming / client time info.  Or perhaps they do.  In any event...)  The usual way is first demonstrated in my 
SNTP (simple NTP) web project (<a href='https://github.com/kwynncom/sntp-web-display'>GitHub</a>, <a href='https://kwynn.com/t/9/11/sntp/'>live</a>).  
</p>

<p>During those explorations, I found the <a href='https://chrony.tuxfamily.org/'>chrony</a> implementation of the network time protocol (NTP).  This both keeps "super" accurate time, depending 
on conditions, and it tells you how your machine compares to "official" time.  That kept me happy for a while, but then I started wondering about the numbers chrony gives me.
</p>

<p>So I updated the web SNTP code and made a <a href='https://github.com/kwynncom/code-fragments/tree/2718ee05278ceee9d980f1799d3fb81884fbba13/sntp'>command line (CLI command line interface) version</a>.  (Note that in that case I'm linking to a specific version because that code will likely move soon.)  In good conditions, that matches chrony's time estimate well enough.  Good conditions are AT&T U-Verse DSL at a mere 14 Mbps download speed accessed through wifi with 60 - 80% signal strength.  Both U-Verse and my wifi signal are very, very stable.  (I think it's still 
called DSL, even after ~22+ years.  It involves something that looks like a plain old telephone line, although I can't be sure it's the same local wireing as 40 years ago.)  
</p>

<p>I can use the "chronyc tracking" command to get my time estimate, or I wrote a <a href='https://github.com/kwynncom/code-fragments/tree/8a7b088f7671efec52a284532f4965c9f729dc00/chronyc'>tabular form of it</a>.  </p>

<p>Below are my chrony readings as of moments ago (5:40pm my time).  I'm removing some less-relevant rows.</p>

<pre>
/chronyc$ php ch.php
 mago    uso    rdi      rf    sk   rde      f
145.3     +0  50.91    -0.18  13.1   65   -7.794 
 96.3   +719   1.40    40.71  13.1   36   -7.794 
 95.2    -56   0.97    -0.20  10.5   37   -1.487 
 89.3    -63   1.59    -0.05   1.9   36   -5.476 
  1.8    +10   1.06    -0.00   0.3   36   -7.450 
</pre>

<p>Weeks later...  I'm going to let this post die right here, at least for now.  I hadn't posted this as of March 3.
</p>


</section>

<section>
<h3>2021, Jan 29 - chrony continued</h3>

<p>As a follow up to my previous entry, now I've set minpoll / maxpoll to 1 / 2 with my cellular network.  THAT gets results.  My offset time 
approaches that of a wired connection, and it's the same with root disperson and skew.  
</p>

</section>


<section>
<h3>2021, Jan 28 - chrony on wired versus wireless</h3>

<p><a href='https://chrony.tuxfamily.org/index.html'>chrony</a> is a Network Time Protocol (NTP) client / server; in other words, it helps 
computers keep accurate time by communicating time "readings" over the internet.
</p>

<p>In the last few weeks I have set chrony to use kwynn.com as its time source.  Kwynn.com lives on Amazon Web Services (AWS).  AWS has a time service, and my "us-east" AWS region is physically close to the NIST time servers in Maryland.  Right now I have a root disperson and root delay of around 0.3ms, and my root mean square offset from perfect time is 13 microseconds (us or &micro;s).  I have 3 - 5 decimal places after that, but I won't bore you any more than I already am.  The point being that it's probably just as good or better than using the NIST servers.  
</p>

<p>I've tested kwynn.com versus using it plus other servers in the Ubuntu NTP pool, and kwynn.com is much, much better.  This is one of several stats that I may quantify one day, but I want to get the key point out because I found it interesting and want to record it for myself as much as anything.
  </p>

<p>Among other features, chrony has the "chronyc tracking" command that gives you an estimate of your clock's accuracy and various statistics around that estimate.  Then I check check chronyc against I script I wrote that polls other servers and outputs the delay, including an arbitrary number of polls of kwynn.com.  Sometimes I'll query kwynn.com 50 times, seeking the fastest turnaround times which in theory should be the best.  I call this my "burst" script.
</p>

<p>On AT&T UVerse (I think that's still "DSL.") at what is probably the slowest available speed (14 Mbps / 1.4 MBbs), chrony is very stable.  What chrony says versus "the burst" is very close.  
</p>

<p>On my T-Mobile (MetroPCS) hotspot, things get more interesting.  Sometimes when I cut over from AT&T to wireless, my time gets pretty bad and the chronyc readings are very unstable.  This evening it was so bad that I changed my minpoll / maxpoll to 2 / 4.  (Depending on my OCD and my mood, I tend to have it on 4 - 5 / 6 - 7.)  Note that you should not use such numbers or even close with the NTP poll, and you may or may not get away with it using NIST--please check the fine print.  
</p>

<p>When I set min / max to 2 / 4, that's when things got interesting.  On one hand, the chronyc numbers stabilize to the point that they get close to wired numbers.  On the other hand, comparison to "the burst" is not nearly as "convincing" / close as wired.  That is, chrony claims accuracy in a range of 100 - 300 us, but it's hard to get a "burst" to show 3 - 4 ms.  The burst almost never shows time as good as chrony claims, but that's another discussion.
</p>

<p>Otherwise put, with a low poll rate on wireless, chronyc claims to be happy and shows good numbers, but agreement with the burst is not nearly as close.
</p>

<p>This is mostly meant as food for thought, and perhaps I'll give lots of gory details later.  I mainly wanted to record those 2 / 4 numbers, but I thought I'd give some context, too.

</p>



</section>

<section>
	<h3>2021, Jan 23 - detecting sleep / hibernate / suspend / wakeup in Ubuntu 20.04</h3>
	<p>In Ubuntu 20.04 (Focal Fossa), executables (including scripts with the x bit set) placed in /lib/systemd/system-sleep/ will run 
	upon sleep / hibernate / suspend and wakeup.  This is probably true of other Debian systems.  I mention this because for some distros it's
	/usr/lib/systemd/system-sleep/
	</p>
	<p>One indicator I had is that the directory itself already existed and 2 files already existed in it: hdparm and unattended-upgrades.  
	There are some comments out there that /lib/... is correct for some Debian systems, but I thought this was worth writing to confirm.  
		</p>
	<h4>example script</h4>
	<pre>
/lib/systemd/system-sleep$ sudo cat kw1.sh
#!/bin/bash 
echo $@ >> /tmp/sleeplog
whoami  >> /tmp/sleeplog
date    >> /tmp/sleeplog
	</pre>
	<p>The bits:</p>
	<pre>/lib/systemd/system-sleep$ ls -l kw1.sh
-rwxrwx--- 1 root root 158 Jan 23 18:18 kw1.sh
	</pre>
	<p>output:</p>
	<pre>
$ cat /tmp/sleeplog
pre suspend
root
Sat 23 Jan 2021 01:39:49 AM EST
post suspend
root
Sat 23 Jan 2021 06:08:02 PM EST
	</pre>

<p>The very careful reader will note that the script above is less than 158 bytes.  I added a version number and a '******' delimeter 
after the first version.  I'm showing just the basics, in other words, and I'm showing the parts that I know work.

</p>
		
</section>

<section id='2020-1120-arb-file-music'>
<h3>2020, Nov 20 - arbitrary files played as "music"</h3>

<p>As part of my now-successful quest for <a href='https://github.com/kwynncom/true-random-numbers-from-microphone'>randomness from the microphone</a>, I came across 
    non-randomness from a surprising place.  I generated the following audio file with these steps:
</p>

<pre>
dd if=~/Downloads/ubuntu-20.04.1-desktop-amd64.iso of=/tmp/rd/raw.wav bs=2M count=1
ffmpeg -f u8 -ar 8k -ac 1 -i /tmp/rd/raw.wav -b:a 8k /tmp/rd/ubulong.wav
ffmpeg -t 1:35 -i /tmp/rd/ubulong.wav /tmp/rd/ubu95s.wav
chmod 400 /tmp/rd/ubu95s.wav
mv /tmp/rd/ubu95s.wav /tmp/rd/ubuntu-20-04-1-desk-x64-95-seconds.wav
</pre>

<p><span style='font-size: 120%; font-weight: bold'>Turn your speakers down!</span> to about 1/4 or 1/3 of full volume.  I now 
    present <i>Ubuntu Symphony #1</i> - opus 20.04.1.1. There is a bit 
of noise for less than 2 seconds, then about 3 seconds of silence, and then nearly continuous sound. </p>

    <div>
        <button onclick='play2020_1();' >play Symphony #1</button>
		<span style='padding-left: 1ex; '>
		<button style='font-size: 120%' onclick='play2020_1(false);'>stop
		</button></span>
    </div>

<p>I posted several versions quickly; the final version was posted at 6:27pm on posting day.</p>

<p>I'm adding some <a href='#misc_files_as_audio_2_2021_12_1'>discussion a year later</a>.
    
</p>

</section>


<section>
<h3>2020, Oct 15 - SEO</h3>

<p>In the last few weeks I finally took a number of SEO steps for this site.  I'd been neglecting that for years.  I registered the httpS version of kwynn.com with Google, and I created a new sitemap with a handful of httpS links.  
</p>


<p>A few weeks after the above, I got some surprising Google Search Console results.  I have 247 impressions over 3 months for <a href='https://kwynn.com/t/8/02/pacer/pacer.html'>my PACER page</a>.  I only have 6 clicks, and I suspect that's because the page's Google Search thumbnail / summary / whatever shows an update date of November, 2017, which is incorrect.  Soon I am going to attempt to improve that click through rate.

</p>

</section>

<section id='2020-1007-entry2'>
<h3>limitations of RAM, speed, etc.  2020, Oct 7 - entry 2 of the day</h3>

<p>My only active apprentice just bought an ArduinoBoy in part because he is fascinated to wrestle with 1980-era limitations of RAM and such.  As I discussed with him, I am not disuading him from that.  However, I wanted to give him something to think about.
</p>

<p>Last night I managed to crash several processes and briefly locked up my session because I didn't consider that there are still limitations on relatively modern hardware.  It's much harder to do that much (temporary) damage today than it was in 1995 or 2003, but it's still possible.  
</p>

<p>Generally speaking, I was testing something that involved all cores at once and as many iterations as I could get.  I got away with 12 cores times 2M iterations (24M data points total).  Then I ran that again without wiping my ramdisk (ramfs), so I was able to test 48M data points.  Then when I tried to run 12 X 8M = 96M, my system went wonky.  
</p>

<p>I have not done a post-mortem or simple calculations to know what specifically went wrong.  I probably exceeded the RAM limitation set in  php.ini.  I may have exceeded system RAM, but I don't think so.  What is odd is that my browser crashed, and it was just sitting there innocently.  It was not involved in the wayward code.  All the CPUs / cores were pegged for a number of seconds, but that shouldn't have that 
effect.
</p>

<p>Maybe he'll want to figure out what went wrong and how to most efficiently accomplish my testing?  </p>

<p>On a related point, one thing I learned is that file_put_contents() outputing one line at a time simultaneously from 12 cores does not work well, which makes perfect sense with a few moments of thought.  So I saved the data in a variable until the "CPU stuff" was done and then wrote one file per process.  (fopen and fwrite were not notably faster in that case.)
</p>

<p>So how do I accomplish the testing I want with as many data points as possible, as fast as possible, without crashing my session (or close enough to crashing it)?  The question of limitations applies on a modern scale.
</p>

<p>Apparently the <a href='https://github.com/kwynncom/readable-primary-key/blob/11dc4ab2e0b8dff7559d275c37b2d6d886ec6562/collisions/v3/r3.php'>current version of the code</a> is still set for 96M rows.  The October 3 entry of <a href='https://kwynn.com/t/20/10/github_guide.html'>my GitHub guide</a> explains what I was doing to a degree.  I'll hopefully update that page again sometime this week, and try to explain it better.
</p>

<p>I also observed several weeks ago that forking processes in an infinitely loop will very thoroughly crash the (boot) session to the point of having to hold down the start button.  Up until very roughly 2003, when I was still using Satan's Operating System, any infinite loop would crash the session.  Now a client-side JS infinite loop will simply be shut down by the browser, and similarly contained in other situations.  But infinitely forking processes on modern Ubuntu will get you into trouble.  I suppose that's an argument for both a VM and imposing quotas.  I took the quota route.  
</p>


<p>As best I remember, the code in question was around <a href='https://github.com/kwynncom/aws-ec2-metrics-web-display/blob/7b678b6c6c06fb2cb7a6a4d7162dec0fc261e942/pcontrol/pcontrol.php'>this point (AWS EC2 / CPU metrics process control)</a>.

</p>

</section>

<section id='dev_rules_3_4'>
<h3>new rules of software dev - numbers 3 and 4 - 2020, Oct 7 entry 1 of the day</h3>

<p>The first two rules are at the <a href='#dev_rules_1_2'>beginning</a> of this blog.</p>

<section>
<h4 style='display: inline'>Kwynn's rule of software dev #3:</h4> <p  style='display: inline'>Never let anyone--neither the client nor other devs--tell you <b>how</b> to do something.  The client almost by definition tells you what he wants done, not how.
</p>
</section>

<p>This applies mainly for freelancing, or perhaps one should freelance in order to not violate the rule.</p>

<p>I should have formulated this in 2016 or 2017.  I finally had one last incident in the summer of 2020 that caused me to formalize it, and now I'm writing it out several weeks later.  </p>

<p>To elaborate on the rule, if you know all the steps necessary to do something in a certain way, do it.  After it's done your way, no one is likely to argue with you.  If you try to do it someone else's way, you are likely to waste a lot of time and money.  
</p>

<p>An example is beware of when the client requests that you do the quick fix.  If your way is certain and the quick fix is uncertain, by the time you do the quick fix, you would have both fixed the problem and had a better code base by doing it your way.
</p>

<p>Another statement of the rule is to beware of assuming that others know more than you do.  Specifically beware of those who you may think are developers but are actually developer managers or salespeople with delusions of developing.  I once knew a developer manager who exemplified the notion "He knows just enough to be dangerous."  He led me into danger.
</p>

<section>
<h4 style='display: inline'>Kwynn's rule of software dev #4:</h4> <p  style='display: inline'>Custom-written software is often the best long-term solution.  Be very careful of content management systems, ERP systems, e-commerce systems, etc.</p>

<p>To quote a comedian from many decades ago, "I went to the general store, but I couldn't buy anything specific."  That reminds me of WordPress, Drupal, OpenERP (I doubt Odoo is any better.), etc.  There is plenty more to say on this, but it will have to wait.
</p>

</section> <!-- rule 4-->



</section> <!-- rules 3 and 4 -->



<section>

<h3>July 18, 2020</h3>

<p>Some words on JavaScript var, let, const.  I'll admit to still being fuzzy on some fine points, but here are some rules of thumb I've come up with that are well battle tested:</p>

<ul>

<li>In order of const, let, var, if you can make a variable of that type, do it.  That is, if you can make it a const, do it first.  If you can make it a let, do it next.
</li>

<li>Objects (and I think arrays) are almost always eligible for const.  The contents of the object / array may change, but that doesn't change the variable itself, so make objects (and arrays) const.
</li>

<li>Similarly, you can almost always make the variable a let if not a const.  In most cases, if you can't make it let, you're probably doing something inadvisable.
</li>

<li>I don't remember for sure, but I think you can make global variables const, so do it if they are indeed a constant.  An example would be that constant globals occur when you first load a page and initilize it with data from the server.  Yes, creating global variables should be questioned, but I still find them useful.
</li>

</ul>

</section>


<section>

<h3>June 21, 2019</h3>

<p>Over the last several weeks, I ran into 5 - 6 very thorny problems.  Let's see if I can count them.  About all I'm good for at this moment is writing gripy blog posts, if that.</p>

<p>My June 12 entry refers you to the drag and drop problem and the hard refresh problem.  Those are 2 of the problems.
</p>

<p>I just wrote <a href='https://kwynn.com/t/9/01/prpp/bridge_mitm.html'>an article on networking bridging and using MITM</a> (man in the middle) "attacks" / monitoring.  Getting both of those to work was a pain.  The bridging took forever because the routing table kept getting messed up.  The MITM took forever because it took me a lot of searching to find the necessity for the ebtables commands.
</p>

<p>After I solved the Firefox problems mentioned on June 12, I ran into another one.  The whole point of my "exercise" for calendar months (weeks of billable time) was to rewrite the lawyer ERP timecards such that they loaded many times faster.  They were taking 8 seconds to load, and *I* did not write that code.  
</p>

<p>Load time was instant on my machine.  Everything was good until I uploaded the timecard to the Amazon nano-instance.  Then the timecards took 30 - 45 seconds to load.  The CPU was pegged that whole time.  So, I'm thinking, my personal dev machine is relatively fast.  The nano instance is, well, nano.  So, I figured, <a href='https://www.youtube.com/watch?v=cVsQLlk-T0s'>"More cowbell!"</a>.  At a micro-instance, RAM goes from 0.5 GB to 1GB.  That appeared to be enough to keep the swap space usage to near zero.  No help.  Small--nope: no noticable change.   At medium, CPUs go from 1 to 2.  Still no change.  I got up to the one that costs ~33 cents an hour--one of the 2xlarge models with 8 CPUs.  Still no change.  WTF!?!
</p>

<p>I had started to consider the next generation of machines with NVMe (PCI SSDs).  My dev machine has NVMe, so maybe that's part of the problem.  However, iotop didn't show any thrashing.  It was purely a CPU problem.  
</p>

<p>So, upon further thought, it was time to go to the MySQL ("general") query log.  The timecard load was so slow that I figured I might see the query hang in real time.  Boy, did I ever!  I found one query that was solely responsible.  It took 0.13s on my machine and 46s on an AWS nano (and much more powerful).  That's 354x.  
</p>

<p>The good news was that I wrote the query, so I should be able to fix it, and it wasn't embedded hopelessly in 50 layers of Drupal feces.  (I did not choose Drupal.  I sometimes wish I had either passed on the project or seized power very early in my involvement.  My ranting on CMSs will come one day.)  
</p>

<p>I thought I isolated which join was causing trouble by taking query elements in and out.  I tried some indexes.  Then I looked at the explain plan.  It's been a long time since I've looked at an explain plan, but I didn't see anything wrong.  
</p>

<p>My immediate solution was to take out the sub-feature that needed the query.  That's fine with my client for another week or two.  Upon yet more thought, I should be able to solve this easily by using my tables rather than Drupal tables.  I've written lots of my own tables to avoid Drupal feces.  It turns out that using my tables is a slightly more accurate solution to the problem anyhow.  
</p>

<p>One of the major benefits of using AWS is that my dev machine and the live instance are very close to identical in terms of OS version, application versions, etc.  So this is an interesting example of an exponential effect--change the performance characteristics of the hardware just a bit, and your query might go over the cliff.  
</p>


<p>I guess it's only 5 problems.  It seemed like more.</p>
</section>


<section>
<h3>June 12, 2019 - a week in the life</h3>

<p>I created a <a href='https://kwynn.com/t/8/01/Firefox_reload_bug.html'>new page on some of my recent frustrations</a>--frustrations more than achievements.  We'll call it "a week in the life."  I thought browser differences were so 2000s or 200ns (2000 - 2009).  

</p>


</section>

<h3>March 9, 2018 - upgrading MongoDB in Ubuntu 17.10</h3>

<p>This started with the following error in mongodump:</p>

<code>
Failed: error dumping metadata: error converting index (&lt;nil&gt;): conversion of BSON value '2' of type 'bson.Decimal128' not supported
</code>

<p>Here is my <a href='http://kwynn.com/t/8/03/MongoDB_upgrade_Ubuntu.html'>long-winded solution</a>.  

</p>



<h3>March 8, 2018 - anti-Objectivist web applications</h3>

<p>
I was just sending a message on a not-to-be-named website, and I discovered that it was eliminating the prefix "object" as in "objective" and "objection."  It turned those words into "ive" and "ion."  Of course, it did it on the server side, silently, such that I only noticed it when I read my already-sent message.  The good news is that the system let me change my message even though it's already sent.  I changed the words to "tangible" and "concern."  
</p>
<p>
I have been teaching my apprentice about SQL injection and what I call the "Irish test":  Does your database accept "O'Reilly" and other Irish names?  This is also a very partial indication that you are preventing SQL injection.  Coincidentally, I emailed a version of this entry to someone with such an Irish name.  So far, sending him email hasn't crashed GMail.  They probably use Mongo, though.
</p>
<p>
If you haven't guessed, what's happening in this case is eliminating "object" because it might be some sort of relative to SQL injection.  I thought I've seen evidence that the site is written in PHP, but, now that I look again, I'm not as sure.  This is knowable, but I don't care that much.  I don't think "object" is a keyword in either PHP or JavaScript.  (Yes, I suppose I should know that, too, but what If I chased down every little piece of trivia?!)  In any event, someone obviously got a bit overzealous, no matter what the language.
</p>

<p>
I will once again posit to my apprentice that I don't make this stuff up.
</p>


<p>
The final word on SQL injection is, of course, <a href='https://xkcd.com/327/'>this XKCD comic</a>.  I must always warn that I am diametrically opposed to some things Munroe has said in his comic.  I would hope he goes in the category of a public figure, and thus I can call him an idiot-savant.  Then again, he more or less calls himself that about every 3rd comic.  He's obviously a genius in many ways, but he epically misses some stuff.  One day, this tech blog might go way beyond tech, but I'm just not quite there yet, so I'm not going to start exhaustively fussing at Randall.
</p>


<h3>Mar 1, 2018 - LetsEncrypt / certbot renewal</h3>

<p>This is the command for renewing an SSL cert "early":</p>
<code>sudo certbot renew --renew-by-default</code>

<p>Without the --renew-by-default flag, I can't seem to quickly figure out what it considers "due for renewal."  Without the flag, you'll get this:
</p>

<pre>
The following certs are not due for renewal yet:
  /etc/letsencrypt/live/[domain name]/fullchain.pem (skipped)
No renewals were attempted.
</pre>

<p>I should have the <a href='https://letsencrypt.org/docs/rate-limits/'>rate limits</a> / usage quotas under "rate limits."

</p>

<p>An update, moments after I posted this: the 3 week renewal emails are for the "staging" / practice / sandbox certs, not the live / real ones.  I wonder when or if I'd get the live email?  Also, I won't create staging certs again, so those won't help remind me of the live renewals again.  I'll put it on my calendar--I'm not relying on an email--but still somewhat odd.
</p>

<p>The email goes to your address in your /etc/letsencrypt/.../regr.json file, NOT the Apache config.  I say ... because the path varies so much.  grep -iR [addr]   will find it.  
</p>


<h3>Feb 2, 2018 - base62</h3>

<p>Random base64 characters for passwords and such annoy me because + and / will often break a "word"--it's hard to copy and paste the string, depending on the context.  Thus, I present base62: the base64 characters minus + and /.  I considered commentary, but perhaps I'll leave that as the infamous "exercise to the reader."  However, I do have a smidgen of commentary below.
</p>

<p>Note, as of 2022/01/05, I am replacing the less-than sign of the php tag with an HTML less-than entity, because the real PHP 
    tag disrupts the NetBeans editor.  The current version if this code is 
    <a href='https://github.com/kwynncom/kwynn-php-general-utils/tree/e4a442f634192534d1b22176b1d992cadba52750/base62'>now in GitHub</a>. 
    
</p>

<textarea rows='15' cols='78'>
#! /usr/bin/php
&lt;php
// random base62 - Kwynn.com, 2018/02/02 3:11AM EST, UQID: VMbAlZQ13ojI

$len = 20; // default length of random string
if ($argc  > 1) $len = intval($argv[1]); // length as argument
if (($len) < 1) die('invalid length' . "\n");

$basea = [ord('A'), ord('a'), ord('0')]; // preg [A-Za-z0-9]

for ($i=0, $rs = ''; $i < $len; $i++)
   for ($j=0, $ri = random_int(0, 61); $j < count($basea); $j++, $ri -= 26)
	if ($ri < 26) { $rs .= chr($basea[$j] + $ri); break; }

echo $rs . "\n";
</textarea>

<h4>Example</h4>

<p>Assuming you call the file base62.php, give it exe permission, and execute from the Linux command prompt:</p>

<pre>
./base62.php 50
vjQBjFxJGcotOpxVJyvG1CUQ11010xigP1RyuKza120JWeFkeI
</pre>

<h4>Validation</h4>

<pre>./base62.php 1000 | grep -P [ANZanz059]</pre>

<p>That's my validation that I see the start, end, and midpoints of my 3 sets (arrays) of characters.</p>

<h4>UQID</h4>

<p>In the event that Google doesn't look inside the textarea, UQID: VMbAlZQ13ojI.  That was generated with my brand new scriptlet.  So far that string is not indexed by Google.  UQID as in unique ID.  Or temporarily globally unique ID.  Or currently Google unique ID (GOUID?). Presumably it isn't big enough to be unique forever.  62^12 = 3 X 10^21.  That's big but not astronomical.  :)
</p>

<h4>somewhat-to-irrelevant commentary</h4>

<p>What can I say?  Sometimes I amuse myself.  Ok.  My structure is on the obtuse side.  I couldn't help it.  I usually don't write stuff like that.  Perhaps Mr. 4.6 or one of my more recent contacts can write the clearer version.  I actually did write clearer versions, but, then, I couldn't help myself.

</p>

<h4>further exercise to the reader</h4>

<p>Perhaps someone will turn this into a web app?  Complete with nice input tags and HTML5 increase and decrease integer arrows and an option to force SSL / TLS and AJAX.

</p>

<h4>installing</h4>

<pre>
sudo cp base62.php /usr/bin
cd /usr/bin
ln -s ./base62.php base62
cd /tmp
base62
[output =] RyH3HjGnEalr71meSJfm
</pre>

<p>Now it's part of my system.  I changed to /tmp to make sure that . PATH wasn't an issue--that it was really installed.

</p>


<h4>Reference</h4>

<ul>
<li><a href='http://php.net/manual/en/function.random-int.php'>http://php.net/manual/en/function.random-int.php</a></li>
<li><a href='http://php.net/manual/en/function.ord.php'		  >http://php.net/manual/en/function.ord.php</a></li>
<li><a href='http://php.net/manual/en/function.chr.php'		  >http://php.net/manual/en/function.chr.php</a></li>
</ul>




<h3 id='probe1'>Jan 28, 2018 - Stratego / Probe</h3>

<p>I'd like to recommend Imersatz' <a href='http://www.probe.imersatz.com/'>Stratego board game implementation called Probe</a>.  It is the 3 time AI Stratego champion.  The AI plays against you.  It's a free download; see the "Download" link on that page.  From a human who is good at the game's point of view, I would call it quasi-intelligent, but it beats me maybe 1 / 7 times, so it's entertaining.  
</p>

<p>I am running the game through WINE, the Windows Emulator for Linux.  I just downloaded it to make sure it matches what I downloaded to this new-to-me computer months ago.  It does.  Below I give various specs.  Those are to make sure you have the same thing I do.  It hasn't eaten my computer or done anything bad.  I have no reason to think it's anything but what it says it is.  In other words, I am recommending it as non-malware and fun.  If it makes you feel any better, you can see <a href='https://kwynn.com/t/7/11/blog.html#probe1'>this page in secure HTTP</a>.
</p>

<pre>
Probe2300.exe [the download file]
19007955 bytes
or 19,007,955 bytes / ca. 19MB
SHA512(Probe2300.exe)= e96f5ee67653eee1677eb392c49d2f295806860ff871f00fb3b0989894e30474119d462c25b3ac310458cec6f0c551304dd2aa2428d89f314b1b19a2a4fecf82
SHA256(Probe2300.exe)= ee632bcd2fcfc2c2d3a4f568d06499f5903d9cc03ef511f3755c6b5f8454c709
</pre>

<p>The above is the download file from Imersatz.  In the probe exe directory, I get:</p>

<pre>
1860608 [bytes] Feb 28  2013 Probe.exe
 800611         Feb 28  2013 Probe.chm
1291264         Feb 28  2013 ProbeAI.dll

SHA256(ProbeAI.dll)= 13e862846c4f905d3d90bb07b17b63c915224f5a8c1284ce5534bffcf979537a
SHA256(Probe.chm)= 3b7be4e7933eee5d740e748a63ea0b0216e42c74a454337affc4128a4461ea6b
SHA256(Probe.exe)= 656f31d546406760cb466fcb3760957367e234e2e98e76c30482a2bbb72b0232
</pre>


<h3>Jan 14, 2018 - grudgingly dealing with Mac (wifi installation)</h3>

<p>The first time Mr. 4.6 installed Ubuntu Linux (17.10 - Artful Aardvark) on his Mac laptop (MacBook Pro?), wifi worked fine "out of the box."  I think that's because he was installing Linux via wifi.  This time, he used ethernet, and wifi wasn't recognized--no icon, no sign of a driver.  Because he was using ethernet, maybe the installer didn't look for wifi?  Maybe he didn't "install 3rd party tools"?  (I asked him about that, but he was busy being excited that we fixed it.  I'll try to remember to ask again.)  There were good suggestions on how to fix it out there, but I derived the simplest one:</p>

<p>
<code>
sudo apt-get install bcmwl-kernel-source
</code>
</p>
<p>He didn't even have to reboot.  His wifi icon just appeared.</p>

<p>For the record, that's "Broadcom 802.11 [wifi] Linux STA wireless driver source."</p>

<p>Thanks to <a href='https://www.cberner.com/2017/12/03/installing-ubuntu-17-10-macbook-pro-retina-mid-2012/'>Christopher Berner</a> who got me very close.  He was suggesting a series of Debian packages, but the above command installed everything in one swoop.
</p>

<p>There are a few questions I have for 4.6 about this.  Hopefully I'll get answers tomorrow or later.  

</p>

<h3>Jan 3, 2018</h3>

<h4>JavaScript drag and drop</h4>
<p>I created a <a href='http://kwynn.com/t/8/01/drag_and_drop.html'>JavaScript drag and drop example</a>.  I may have done it in JQuery a handful of times, but I don't remember for sure.  This is a "raw" JS version--no JQuery or other libraries.  I've been thinking about writing a to do list organizer which would use drag and drop.  Also, I might use it professionally soon.
</p>


<h4>new-to-HTML5 semantic elements / tags</h4>

<p>Last night, my apprentice Mr. 4.6 showed me <a href='https://www.w3schools.com/html/html5_semantic_elements.asp'>these new HTML5 elements / tags</a>.   I remember years ago looking for a list of everything that is new in HTML5.  I suspect I've at least heard of 75% of it from searching on various stuff, but I did not know about some of those tags.  I would hope there is good list by now.  Maybe I'll look again or 4.6 will find one.
</p>


<h3>Dec 24, 2017 - remote MongoDB connections through Robo 3T / ssh port forwarding</h3>

<p>A new trick to my Linux book:</p>

<pre>
ssh -L 27019:127.0.0.1:27017 ubuntu@kwynn.com -i ./*.pem
</pre>

<p>That forwards local port 27019 to kwynn.com's 27017 (MongoDB), but from kwynn.com's perspective 27017 is a local port (127.0.0.1 / localhost).  Thus, I can connect through Robo 3T ("the hard way" / see below) to MongoDB on Kwynn.com without opening up 27017 to the world.  In Robo 3T I just treat it like a local connection except 27019.  (There is nothing special about 27019.  Make it what you want.  Thanks to <a href='https://github.com/simsekgokhan'>Gkhan imek</a> who gave me this idea / solution / technique in <a href='https://github.com/Studio3T/robomongo/issues/1354#issuecomment-303067420'>this comment</a>. )
</p>

<p>I used this because I am suffering from a variant of the ssh tunneling bug in 3T 1.1.  (I solved it.  See below.)  I think I have a different problem than most report, though.  Most people seem to have a problem with encryption.  I'm not having that problem because this is what tail -f /var/log/auth.log shows:
</p>

<pre>

I suspect the Deprecated stuff is irrelevant:

Dec 24 00:11:11 kwynn.com sshd[18675]: rexec line 16: Deprecated option UsePrivilegeSeparation
Dec 24 00:11:11 kwynn.com sshd[18675]: rexec line 19: Deprecated option KeyRegenerationInterval
Dec 24 00:11:11 kwynn.com sshd[18675]: rexec line 20: Deprecated option ServerKeyBits
Dec 24 00:11:11 kwynn.com sshd[18675]: rexec line 31: Deprecated option RSAAuthentication
Dec 24 00:11:11 kwynn.com sshd[18675]: rexec line 38: Deprecated option RhostsRSAAuthentication
Dec 24 00:11:12 kwynn.com sshd[18675]: reprocess config line 31: Deprecated option RSAAuthentication
Dec 24 00:11:12 kwynn.com sshd[18675]: reprocess config line 38: Deprecated option RhostsRSAAuthentication
[end deprecated]

Dec 24 00:11:12 kwynn.com sshd[18675]: Accepted publickey for ubuntu from [my local IP address] port 50448 ssh2: RSA SHA256:[30-40 base64 characters]
Dec 24 00:11:12 kwynn.com sshd[18675]: pam_unix(sshd:session): session opened for user ubuntu by (uid=0)
Dec 24 00:11:12 kwynn.com systemd-logind[960]: New session 284 of user ubuntu.
Dec 24 00:11:12 kwynn.com sshd[18729]: error: connect_to kwynn.com port 27017: failed.
Dec 24 00:11:12 kwynn.com sshd[18729]: Received disconnect from [my local IP address] port 50448:11: Client disconnecting normally
Dec 24 00:11:12 kwynn.com sshd[18729]: Disconnected from user ubuntu [my local IP address] port 50448
Dec 24 00:11:12 kwynn.com sshd[18675]: pam_unix(sshd:session): session closed for user ubuntu
Dec 24 00:11:12 kwynn.com systemd-logind[960]: Removed session 284.
</pre>

<p>For the record, the error I get is "Cannot establish SSH tunnel (kwynn.com:22). / Error: Resource temporarily unavailable. Failed to create SSH channel. (Error #11)."
</p>

<p>This doesn't seem to be an encryption problem, though, because my request is clearly accepted.  MongoDB is bonded to 127.0.0.1--internal connections only--but this shouldn't be a problem because based on traceroute my system knows that IT is kwynn.com (It "knows" this in /etc/hosts).  It doesn't try routing packets outside the machine.
</p>

<p>On the other hand, this won't work in the sense that 3T won't connect:</p>

<pre>
ssh -L 27019:kwynn.com:27017 ubuntu@kwynn.com -i ./*.pem
</pre>


<h4>Solution</h4>

<p>Huh.  I just fixed my problem.  If I put kwynn.com in /etc/hosts as 127.0.1.1 then 3T won't work through "manual" ssh forwarding (like my command above), even if I forward as 127.0.1.1.  If I put kwynn.com in /etc/hosts as 127.0.0.1, 3T works 3 ways: either through the above (127.0.0.1) OR this: </p>

<pre>
ssh -L 27019:kwynn.com:27017 ubuntu@kwynn.com -i ./*.pem
</pre>

<p>AND 3T works without my "manual," command ssh port forwarding, through it's own ssh tunnel feature, which solves my original problem.  However, I'm glad I learned about ssh port forwarding.
</p>

<p>I need to figure out what the difference is between 127.0.1.1 and 0.1.  AWS puts the original "name" of the computer in /etc/hosts as 127.0.1.1 by default, and I just read instructions to use 127.0.1.1.  Oh well, for another time...

</p>





<h3 id='sslCertAnnouncement20171'>December 21, 2017 - kwynn.com has its first SSL cert, Mongo continued</h3>

<p>I'm starting to write around 11:08pm.  I'll probably post this to test the link just below, then I should write more.

</p>

<h4>SSL</h4>

<p>Kwynn.com has its first SSL certificate.  You can now read <a href='https://kwynn.com/t/7/11/blog.html#sslCertAnnouncement20171'>this entry</a> or anything else on my 
site through TLS / SSL.  I have not forced SSL, though: there's no automatic redirect or rewrite.</p>

<p>I remember years ago (2007 - 2009??), a group was trying to create a free-as-in-speech-and-beer certificate authority (CA).  Now it's done, I've used it, and it's pretty dang cool.  Here are some quick tips:</p>

<ul>

<li>I used the <a href='https://letsencrypt.org/getting-started/'>Let's Encrypt</a> "With Shell Access" procedure</li>

<li>Before using certbot (below), make sure port 443 is open to the world.  I forgot about AWS EC2's firewall ("Security Group")--that I had 80 open but not 443.  That's what caused my site to go down until I remembered (more below)--certbot could not verify that I owned the site because it couldn't reach 443.  In AWS EC2, go to EC2 Dashboard / Network & Security / Security Groups, find the Group associated with your server, and then add 443.
</li>


<li>For Ubuntu, their 17.04 (Zesty Zapus) <a href='https://certbot.eff.org/'>Certbot</a> version works fine in 17.10 (Artful Aardvark).</li>
<li>You DO want to access the Certbot PPA because, as I recall, it's 0.2 versions ahead (0.17.0 v. 0.19.0) of "base" Ubuntu, and I have a vague memory that 0.19.0 worked better.
</li>

<li>You'll want ServerName filled in in your Apache .conf file because certbot will read that and make your life easier.  I can't remember if it read ServerAdmin (admin email) or not.  See my whole .conf file below.
</li>

<li>I started my ssl.conf as a copy of my modified 000-default.conf.  You'll want the conf enabled (sudo a2ensite ssl) so that certbot will see the conf but do NOT reload Apache until you're pretty sure everything is working (see below).

</li>

<li>You definitely want to use the <a href='https://letsencrypt.org/docs/staging-environment/'>staging (sandbox) switch</a> ( --staging  flag) until you have everything right.  I was probably in some danger of exceeding my <a href='https://letsencrypt.org/docs/rate-limits/'>production (non-staging) quota</a>.  You'll get the Chrome / Firefox warning to the effect of "This isn't safe.  Are you sure you want to continue?"  You do want to continue to make sure you get httpS even if it comes with a strikethrough.  Once you have it working that way, then you can rerun the command without staging and have the system overwrite the staging cert / CA / Key files.  
</li>

<li>You should strongly consider using the <a href='https://certbot.eff.org/#ubuntutzesty-apache'>certonly flag</a> / subcommand either always or until you're really sure everything is going to work (such as success with --staging).  Otherwise, if the command fails, your site goes down.  Without "certonly," certbot restarts Apache (graceful(ly), or at least it tries.  If the restart fails, down goes your site.
</li>

</ul>

<h5>my ssl.conf</h5>

<p>Rather than letting certbot mess with your .conf, it should look something like the following.  Once the 3 /etc/letsencrypt files have populated with certbot ... certonly, then you're safe to restart Apache.  
</p>

<p>I included ErrorLog and CustomLog commands to make sure SSL traffic went to the same place as non-SSL traffic.  

</p>

<pre>
&lt;VirtualHost *:443&gt;

	ServerName kwynn.com
	ServerAdmin myemail@example.com

	DocumentRoot /blah
	&lt;Directory /blah&gt;
		Require ssl
	&lt;/Directory&gt;

ErrorLog ${APACHE_LOG_DIR}/error.log
CustomLog ${APACHE_LOG_DIR}/access.log combined

SSLEngine  on
Include /etc/letsencrypt/options-ssl-apache.conf
SSLCertificateFile /etc/letsencrypt/live/kwynn.com/fullchain.pem
SSLCertificateKeyFile /etc/letsencrypt/live/kwynn.com/privkey.pem
&lt;/VirtualHost&gt;
</pre>

<p>That does NOT force a user to use SSL.  "Require" only applies to 443, not 80.  If you want to selectively force SSL in PHP (before using cookies, for example), do something like this: 
</p>

<pre>
    if (!$_SERVER['HTTPS'] || $_SERVER['HTTPS'] !== 'on') {
		header('Location: https://' . $_SERVER['HTTP_HOST'] . $_SERVER['REQUEST_URI']);
		exit(0);
    }
</pre>

<p>As a critique of the above, perhaps the first term should be (!isset($_SERVER['HTTPS']) but what I have above gets rid of the warning in the Apache error log.  I'll try to remember to test this and fix it later.

</p>

<h4>MongoDB continued -- partial SSL</h4>

<p>I started to secure MongoDB with SSL / TLS, but then I noticed the Robo 3T option to use an SSH tunnel.  Since one accesses AWS EC2 through an ssh tunnel anyhow, and I want access only for me, there is no need to open MongoDB to the internet.  I'd already learned a few things, though, so I'll share them.  Note that this is <b>not fully secured</b> because I had not used Let's Encrypt or any other CA yet, and I'm skipping other checks as you'll see.  I was just trying to get the minimum to work before I realized I didn't need to continue down this path.  See <a href='https://docs.mongodb.com/manual/tutorial/configure-ssl/'>Configure mongod and mongos for TLS/SSL</a>.
</p>

<pre>
cd /etc/ssl/
openssl req -newkey rsa:8096 -new -x509 -days 365 -nodes -out mongodb-cert.crt -keyout mongodb-cert.key
cat mongodb-cert.key mongodb-cert.crt > mongodb.pem


Then set up the config file as such:

cat /etc/mongodb.conf

storage:
  dbPath: /var/lib/mongodb
  journal:
    enabled: true

systemLog:
  logAppend: true

net:
  bindIp: 127.0.0.1
  port:   27017
  ssl:
    mode: requireSSL
    PEMKeyFile: /etc/ssl/mongodb.pem

******
Then the NOT-fully-secure PHP part:

&lt;?php
set_include_path('/opt/composer');
require_once('vendor/autoload.php');

$ctx = stream_context_create(array(
	"ssl" => array(
	    "allow_self_signed" => true,
	    "verify_peer"       => false,
	    "verify_peer_name"  => false,
	    "verify_expiry"     => false
	)
    )
);

$client = new MongoDB\Client("mongodb://localhost:27017", 
				array("ssl" => true), 
				array("context" => $ctx)
		);

$dat = new stdClass();
$dat->version = '2017/12/21 11:01pm EST (GMT -5) America/New_York or Atlanta';
$tab = $client->mytest->stuff;
$tab->insertOne($dat);

</pre>


<h3>Dec 18 - MongoDB (with PHP, etc.)</h3>

<p>I started using relational (SQL) databases in 1997.  Finally in the last few years, though, I've seen a glimmer of the appeal of OO / schema-less / noSQL / whatever databases such as MongoDB.  For the last few months I've been experimenting with Mongo for my personal projects.  I'm mostly liking what I'm seeing.  I haven't quite "bitten" or become sold, but that's probably coming.  I see the appeal of simply inserting an object.  On the other hand, I've done at least one query so far that would have been far easier in SQL.  (Yes, I know there are SQL-to-Mongo converters, but the one I tried wasn't up to snuff.  Perhaps I'll keep looking.)
</p>

<p>I've been using <a href='https://www.robomongo.org/'>Robo 3T</a> (v1.1.1, formerly RoboMongo) as the equivalent of MySQL Workbench.  I've liked it a lot.  In vaguely related news, I found it interesting that some of the better Mongo-PHP examples I found were on <a href='https://docs.mongodb.com/php-library/current/reference/method/MongoDBCollection-findOneAndUpdate/'>Mongo's site</a> and not PHP's.  The PHP site seems rather confused about versions.  I'm using the composer PHP-Mongo library.  Specifically, the results of "$ composer show -a mongodb/mongodb" are somewhat perplexing, but they include "versions : dev-master, 1.3.x-dev, v1.2.x-dev, 1.2.0 ..."  At the MongoDB command line, db.version() == 3.4.7.  I don't think Mongo 3.6 comes with Ubuntu 17.10, so I'm not jumping up and down to install "the hard way," although I've installed MDB "the hard way" before.  
</p>

<p>Mostly I'm writing this because I've been keeping that PHP link in my bookmarks bar for weeks.  If I publish it, then I don't need the link there in valuable real estate.  Although in a related case I forgot for about 10 minutes that I put my Drupal database timeout fix on my web site.  Hopefully I'll remember this next time.
</p>


<h3>Dec 17, 2017</h3>

<h4>Today's entry 2 - yet another Google Apps Script / Google Calendar API error and possible Google bug</h4>

<p>I solved this before I started the blog and wrote about the other errors below.  The error was "TypeError: Cannot find function createAllDayEvent in object Calendar."  This was happening when I called "CalendarApp.getCalendarById(SCRIPT_OWNER);" twice within a few lines (milliseconds or less) of each other.  The failure rate was something like 10 - 15% until I created the global.
The solution is something like this:
</p>

<pre>
var calendarObject_GLOBAL = false;

function createCalendarEntry(summary, dateObject) {
	var event = false;
	event = calendarObject_GLOBAL.createAllDayEvent(summary, dateObject);	
}

calendarObject_GLOBAL = CalendarApp.getCalendarById(SCRIPT_OWNER); // calendar object

createCalendarEntry('meet Bob at Planet Smoothie', dateObject123);
</pre>

<p>I'm not promising that runs; it's to give you the idea.  Heaven forbid I post proprietary code, and there is also the issue of taking the time to simplify the code enough to show my point.  I should have apprentices for that (hint, hint).
</p>

<p>I was getting errors when I called CalendarApp... both inside and outside the function.  I suspect there is a race condition bug in Google's code.  We know the hard way how fanatical they are about asynchronicity.  Sometimes that's a problem.
</p>

<p>Yes, yes.  I'm being sarcastic, and I may be wrong in my speculation.  I understand the benefit of all async.  But isn't part of the purpose of a blog to complain?  

</p>


<h4>Today's entry 1</h4>
<p>I just updated my Drupal database connection error <a href='http://kwynn.com/t/7/01/drupal_error.html'>article</a>

</p>

<h3>Dec 6, 2017 - today's entry 2 - fun with cups and Drupal runaway error logs</h3>

<p>I just discovered that /var/log/cups was using 40GB.  Weeks ago I noticed cups was taking 100% of my CPU (or one core, at least) and writing a LOT of I/O.  It was difficult the remove it entirely.  The solution was something to the effect of removing not only the "cups" package but the cups-daemon.  cups is a Linux printing process.  I haven't owned a working printer in about 6 years, and I finally threw the non-working one away within the last year.
</p>

<p>I've had the same runway log problem with Drupal writing 1000s of warnings (let alone errors) to "watchdog."  It took me a long time to figure out that's why some of my Drupal processes were so slow.  It seems that Drupal should simply stop logging errors after a certain number of iterations rather than trash the disk for minutes.  If I cared about Drupal, perhaps I would lobby for this, but I have come somewhere close to despising Drupal, but that's another story for another time.

</p>



<h3>Dec 6, 2017 - fun with systemd private tmp directories</h3>

<p>This happens when you just want to use /tmp from Apache, but no, you get something like /tmp/systemd-private-99a5...-systemd-resolved.service-Qz... owned by root and with no non-root permission. (Yes, yes, I have root access.  That's not the point.)  Worse yet, there are bunch of such systemd directories, so which one are you looking for?  Yes, yes, I'm sure there is a way to know that.  Also not the point.  The point is: please just make it stop!
</p>

<h4>Solution (for Ubuntu 17.10 Artful Aardvark)</h4>

<ol>
<li>with root permission, open for editing: /etc/systemd/system/multi-user.target.wants/apache2.service</li>
<li>Modify this line from true to false:  PrivateTmp=false</li>
<li>run this: sudo systemctl restart apache2.service</li>
<li>I don't think you need to restart apache (see note below), but I'm not sure.  I did restart Apache, but I didn't try it without restarting Apache.</li>
</ol>

<h4>Notes</h4>

<p>I don't even know if restarting the apache2.service is the same thing as restarting Apache or not.  On this point, it is worth noting that sometimes you have to stop going down the rabbit hole, or you may never accomplish what you set out to do.  Yes, I should figure out what this systemd stuff is.  Yes, I should know if the apache2.service is separate from Apache.  One day.  Not when I'm trying to get something very simple accomplished, though.  Also, yes, I understand the purpose of a root-only private directory under /tmp.  Yes, I understand that /tmp is open to all.  But none of that is the point of this entry.  
</p>

<p>If you can't tell, I'm a bit irritated.  Sometimes dev is irritating. 
</p>

<p>For purpose of giving evidence to my night owl cred, I'm about to post at 2:24am "my time" / EST / US Eastern Standard Time / New York time / GMT -5 / UTC -5.  

</p>




<h3>2017, Nov 14 (entry 5)</h3>

<p>I did launch with entry 4.</p>

<p>I just took an AWS EC2 / EBS snapshot of an 8GB SSD ("gp2") volume from my Kwynn.com "nano" instance at US-east-1a.  With my site running, it took around 8 minutes.  The "Progress" showed 0% for 6 - 7 minutes, then briefly showed 74%, then showed "available (100%)."  It ran from 2:55:34AM - around 3:03am.  My JS ping showed no disruption during this time.  CPU showed 0%.  I didn't try iotop.
(Processing almost certainly takes place almost if not entirely outside of my VM, so 0% CPU makes sense.)
</p>

<p>This time seems to vary over the years and perhaps over the course of a day, so I thought I'd provide a data point.

</p>

<section>
<h3>Entry 4 and launch attempt 2</h3>

<p>I wrote entries 1 - 3 at the end of October, 2017, but I have not posted this yet.  I'm writing this on Friday, November 10 at 7:34pm EST (Atlanta / New York / GMT -4).  I mention the time to emphasize my odd hours.  See my <a href='http://kwynn.com/t/6/09/night_owl_developers.html'>night owl developer ad</a>.  
</p>

<p>I'm writing right now because of my night owl company (or less formal association) concept.  My potential apprentice whom I codenamed "Mr. 4.6 Hours" has been active the last few days.  I'd like to think I'm getting better at the balance between lecturing, showing examples, and leaving him alone and letting him have at it.  I think he's making progress, but he's definitely making *me* think and keeping me active.  Details are a longer story for another time.  Maybe I'll post some of my sample code and, eventually, his code.
</p>

<p>He's not around tonight, and I miss the activity.  As I said in the ad, I'd like to get to the point that I always have a "green dot" on Google Chat / Hangouts or whatever system we wind up agreeing on.  </p>

<p>Based on the last few days, I have a better idea of how to word my ad and the exchange I want with apprentices.  Perhaps I'll write that out soon.</p>
</section> <!-- entry 4 -->

<section id='dev_rules_1_2'>
<h2>dev rules 1 and 2</h2>

<p>Rules 1 and 2 and in entries 1 and 3, respectively, below.</p>
<p>Rules 3 and 4 are <a href='#dev_rules_3_4'>way "above"</a> / later.</p>
</section>

<section>
<h3>Entry 3: dev rule #2</h3>

<p>My first GAS and perhaps the 2nd, if it is indeed a server problem, bring up my rule #2:</p>

<p><b>Kwynn's software dev rule #2: always host applications on a site where you have root access and otherwise a virtual machine--something you have near-total control over.</b>  It should be hard to distinguish your control of the computer sitting next to you versus your host.</p>

<p>Amazon Web Services (AWS) meets my definition.  AWS is perhaps one of the greatest "products" I've ever come across.  It does its job splendidly.  When they put the word "elastic" (meaning "flexible") in many of their products, they mean it.  </p>

<p>Others come close.  I used Linode a little bit; it's decent.  I have reason to believe Rackspace comes close.  I am pretty sure that neither of them, though, allow you to lease (32-bit) IP addresses 
like AWS does.  I am reasonable sure getting a 2nd IP address with Linode or Rackspace is a chore--meaning ~$30 and / or human intervention is involved, and / or a delay.  With Amazon, a 2nd IP address takes moments and is free as long as you attach it to an (EC2) instance.
</p>

<p>This rule is less absolute than #1.  Violating always leads to frustration, though, and wasted time.  Whether the wasted time is made up for by the alleged benefits of non-root hosts is a question, but I tend to think not.  I've been frustrated to the point of ill health, though--one of the very few times I've *ever* been sick.  That's a story for another time, though.
</p>

<p>If it's not clear, using GAS violates the rule because of the situation where there is nothing you can do.  I had some who-knows-the-cause problems with AWS in late 2010, but I've never had a problem since.  If, heaven forbid, I did have a problem, I could rebuild my site in another Amazon "availability zone" pretty quickly.  As opposed to just being out of luck with GAS.
</p>

<p>Why I violate the rule with GAS is another story, perhaps for another time.  I'll just say that if it were just me, I'd probably avoid GAS.  With that said, some time I should more specifically praise some features of GAS as it applies to creating a Google Doc.  I was impressed because given the business logic limitations I was working with, GAS was likely easier than other methods.
</p>
</section> <!-- entry 3 -->

<section>
<h3>Entry 2: Google Apps Script and StackOverflow.com</h3>

<p>I've been considering a blog for months if not years.  I finally started because of this problem I'm about to write about.  </p>

<p>This blog entry deals with both the specific problem and a more general problem.</p>

<p>The specific problem was, in Google Apps Script (GAS), "Server error occurred. Please try saving the project again".  The exact context doesn't really matter because if you come across the problem, you know the context.</p>

<p>I spent about an hour chasing my tail around trying variations and otherwise debugging.  At some point I tried to find info on Google itself.  Google referred "us" to StackOverflow.com (SO) with the [google-apps-script] label.  Google declares that to be the official trouble forum.  As it turned out, someone else was having the same problem.  I joined SO in order to respond.  Then roughly 4 others joined in.  We were all having the same problem, and nothing we tried fixed it.  I am 99% sure it was a Google server problem and there was nothing we could do.  The problem continued during that night.  Then I was inactive for ~14 hours.  By then, everything worked.</p>

<p>The more general problem I wanted to address is the way SO's algorithms handled this.  The original post and my response are still there several weeks later.  However, others' perfectly valid responses were removed.  To this day, SO still says, "Because [this question] has attracted low-quality or spam answers that had to be removed, posting an answer now requires 10 reputation on this site..."
</p>

<p>This sort of algorithmic failure troubles me.  I'd like the memory of those deleted posts on the record.</p>

<p>I was motivated to write about this because I encounted another GAS error a few hours ago that I once again suspect is a server error.  This time, I was the one who started the thread.  2 hours later, no one has answered.  I'm curious how this turns out.  I'm not linking to the thread because it's still possible I caused the problem.  Also, I'm not linking to it because Google almost immediately indexed it, so SO is the appropriate place to go.
</p>
</section> <!-- entry 2 -->


<section id='entry1'>
<h3>Entry 1: dev rule #1</h3>

<p><b>Kwynn's Software Dev Rule #1: Never develop without a debugger.</b>  You will come to regret it.  To clarify terms, by "debugger," I mean a GUI-based tool to set code breakpoints, watch variables, etc.  Google Chrome Developer Tools "Sources" tab is a debugger for client-side JavaScript.  Netbeans with Xdebug is a debugger for PHP.  Netbeans will also work with Node.js and Python.  
</p>

<p>It is tempting to violate this rule because you think "Oh, I'll figure it out in another few minutes."  </p>

<p>Another statement of this rule is "If you're 'debugging' with console.log or print or echo, you're in big trouble."

</p>
</section> <!-- all entries -->

<h2>page history</h2>

<ul>
<li>obviously I used dates for all the subsequent entries, so I have not updated this in quite a while, and there is little reason to do so</li>
<li>2020 - Sep 25 - reordering the first entries</li>
<li>2017 - 2020: a number of entries</li>
<li>2017 - November - started</li>
</ul>
<p style='margin-top: 2ex'>
    <a href='https://validator.w3.org/check?uri=https://kwynn.com/t/7/11/blog.html'><img
        src="../../5/02/html5_valid.jpg"
        alt="HTML5 valid" width="103" height="36" /></a>
</p>

</body>
</html>
